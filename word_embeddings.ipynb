{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "19cpujd3495-27jbaKSN3JzjTraxBsgF7",
      "authorship_tag": "ABX9TyNL1/kTDKqHj9ibs3kr7B5G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-atallah/implicit_gender_bias/blob/main/word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Packages"
      ],
      "metadata": {
        "id": "bulYApnKi77K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq8Bmt2cE7e4",
        "outputId": "a3e49069-e826-4da8-da81-694cc7884c9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=67f94789404114129f8cf4b2b4840aba49deeecffbca3156e62b7e3794da6553\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "from pyspark.sql import Row, SparkSession\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XmK1FU53jMVS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Files"
      ],
      "metadata": {
        "id": "HDikGiH9i-nH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These files contain a sample of **social media posts** from the paper *RtGender: A Corpus for Studying Differential Responses to Gender* by Rob Voigt, David Jurgens, Vinodkumar Prabhakaran, Dan Jurafsky and Yulia Tsvetkov. Documentation is available [here](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fnlp.stanford.edu%2Frobvoigt%2Frtgender%2F). The sample includes an equal number of posts from the five data sources balanced on the gender of the original poster. Replacement was used to ensure less robust sources are adequately represented."
      ],
      "metadata": {
        "id": "YtYAQ5V7nRNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdnCHjcWh-3b"
      },
      "outputs": [],
      "source": [
        "filepath = '/content/drive/MyDrive/SIADS 696: Milestone II/Project/Data/RtGender/sample'\n",
        "filepath_train = os.path.join(filepath, 'train_one_million.csv')\n",
        "filepath_validate = os.path.join(filepath, 'validate_one_million.csv')\n",
        "filepath_test = os.path.join(filepath, 'test_one_million.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Load data, rename columns, drop nulls and a specific column\n",
        "dataframe_train = (\n",
        "    spark\n",
        "    .read\n",
        "    .csv(filepath_train, header=True)\n",
        "    .withColumnRenamed(' op_gender', 'op_gender')\n",
        "    .withColumnRenamed(' response_text', 'response_text')\n",
        "    .dropna()\n",
        "    .drop('stratify')\n",
        ")\n",
        "\n",
        "# Display the first five rows of the DataFrame\n",
        "dataframe_train.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYiRelSRpbFY",
        "outputId": "523a6810-9f86-42e1-d0b1-537f8cf659d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---------+--------------------+\n",
            "|source|source_id|op_gender|       response_text|\n",
            "+------+---------+---------+--------------------+\n",
            "|   FIT|FIT262793|        M|oure welcome. Hop...|\n",
            "|   FIT|FIT203911|        M|           Thank you|\n",
            "|   TED|TED129836|        M|As someone that w...|\n",
            "|   TED|TED101922|        M|                Neat|\n",
            "|   RED|RED166641|        W|Seriously. My bat...|\n",
            "+------+---------+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file contains the **stop words** available in the Natural Language Toolkit. Gendered pronouns have been removed."
      ],
      "metadata": {
        "id": "ls_4RchUoTfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_stopwords = '/content/drive/MyDrive/SIADS 696: Milestone II/Project/Data/RtGender/stop_words.txt'"
      ],
      "metadata": {
        "id": "t06GaO5YldGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load stopwords\n",
        "with open(filepath_stopwords, 'r') as file:\n",
        "    stopwords = json.load(file)['stop_words']"
      ],
      "metadata": {
        "id": "XoyGEnfrl0cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file contains **nouns** from the HolisticBias dataset, a project of the Responsible Natural Language Processing team at Facebook Research. The dataset is described in the paper *I'm sorry to hear that: Finding New Biases in Language Models with a Holistic Descriptor Dataset* by Eric Michael Smith, Melissa Hall, Melanie Kambadur, Eleonora Presani, and Adina Williams. Documentation is available [here](https://github.com/facebookresearch/ResponsibleNLP/tree/main/holistic_bias/dataset/v1.1)."
      ],
      "metadata": {
        "id": "00s9B3OPo5Ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath_nouns = '/content/drive/MyDrive/SIADS 696: Milestone II/Project/Data/RtGender/gendered_nouns.txt'\n",
        "filepath_pronouns = '/content/drive/MyDrive/SIADS 696: Milestone II/Project/Data/RtGender/gendered_pronouns.txt'"
      ],
      "metadata": {
        "id": "NwBS1A12lj9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load gendered nouns\n",
        "with open (filepath_nouns, 'r') as file:\n",
        "    nouns = json.load(file)\n",
        "\n",
        "nouns_male = ' '.join([item for sublist in nouns['male'] for item in sublist])\n",
        "nouns_female = ' '.join([item for sublist in nouns['female'] for item in sublist])"
      ],
      "metadata": {
        "id": "4lQ939Xcp-or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file contains **pronouns** from Grammarly as described in the article *A Guide to Personal Pronouns and How They've Evolved*. The article includes additional neopronouns, pronouns that ‚Äúrefer to people entirely without reference to gender‚Äù (Grammarly, 2021). Documentation is available [here](https://www.grammarly.com/blog/gender-pronouns/)."
      ],
      "metadata": {
        "id": "CKXcZqKipUe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load gendered pronouns\n",
        "with open(filepath_pronouns, 'r') as file:\n",
        "    pronouns = json.load(file)\n",
        "\n",
        "pronouns_male = ' '.join(pronouns['male'])\n",
        "pronouns_female = ' '.join(pronouns['female'])"
      ],
      "metadata": {
        "id": "lwj2zRaUmYIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize Text"
      ],
      "metadata": {
        "id": "unXC2QJWjM7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LemmaTokenizer:\n",
        "    \"\"\"\n",
        "    A tokenizer class that optionally applies NLTK's WordNetLemmatizer to both tokens and stop words,\n",
        "    and removes stop words based on a custom JSON file. The class can be configured to perform\n",
        "    lemmatization, stop word removal, both, or neither, ensuring consistency between token and stop word\n",
        "    processing. Based on code developed by Daniel Atallah.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_lemmatization=False, remove_stopwords=False, stopwords_file=None):\n",
        "        \"\"\"\n",
        "        Initializes the LemmaTokenizer instance with options for lemmatization and stop word removal,\n",
        "        and loads (and optionally lemmatizes) stop words from a specified JSON file if stop word removal\n",
        "        is enabled.\n",
        "        \"\"\"\n",
        "        self.use_lemmatization = use_lemmatization\n",
        "        self.remove_stopwords = remove_stopwords and stopwords_file is not None\n",
        "        self.lemmatizer = WordNetLemmatizer() if use_lemmatization else None\n",
        "        self.tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
        "        self.stop_words = self._load_stopwords(stopwords_file) if self.remove_stopwords else set()\n",
        "\n",
        "    def _load_stopwords(self, stopwords_file):\n",
        "        \"\"\"\n",
        "        Loads and optionally lemmatizes stop words from a JSON file.\n",
        "        \"\"\"\n",
        "        with open(stopwords_file, 'r') as file:\n",
        "            stopwords = set(json.load(file))\n",
        "        if self.use_lemmatization:\n",
        "            return {self.lemmatizer.lemmatize(word) for word in stopwords}\n",
        "        return stopwords\n",
        "\n",
        "    def __call__(self, text):\n",
        "        \"\"\"\n",
        "        Tokenizes and optionally lemmatizes and removes stop words from the input text.\n",
        "        \"\"\"\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        if self.use_lemmatization:\n",
        "            tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
        "        if self.remove_stopwords:\n",
        "            tokens = [token for token in tokens if token.lower() not in self.stop_words]\n",
        "        return tokens"
      ],
      "metadata": {
        "id": "vO_UXiUHjRkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_tokenizer(row, text_column, tokenizer):\n",
        "    \"\"\"\n",
        "    Tokenizes text in a specific column of a row.\n",
        "\n",
        "    Parameters:\n",
        "    - row: The row containing the text to tokenize.\n",
        "    - text_column: The name of the column containing the text.\n",
        "    - tokenizer: An instance of a tokenizer class, used to tokenize the text.\n",
        "\n",
        "    Returns:\n",
        "    A new Row object with the original content and an additional 'tokens' field.\n",
        "    \"\"\"\n",
        "    # Tokenize the content of the specified text column\n",
        "    tokens = tokenizer(row[text_column])\n",
        "\n",
        "    # Return a new Row with the original row data and the new 'tokens' field\n",
        "    return Row(**row.asDict(), response_tokens=tokens)"
      ],
      "metadata": {
        "id": "oqnEEIk8s4cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate tokenizer\n",
        "tokenizer = LemmaTokenizer()"
      ],
      "metadata": {
        "id": "f7j5HgkArsPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize dataframe\n",
        "rdd_train = dataframe_train.rdd.map(lambda row: apply_tokenizer(row, 'response_text', tokenizer)).toDF()"
      ],
      "metadata": {
        "id": "hxWyHJWXuTo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize gendered nouns and pronouns\n",
        "tokens_nouns_male = tokenizer(nouns_male)\n",
        "tokens_nouns_female = tokenizer(nouns_female)\n",
        "tokens_pronouns_male = tokenizer(pronouns_male)\n",
        "tokens_pronouns_female = tokenizer(pronouns_female)"
      ],
      "metadata": {
        "id": "6DvbTdX1BLcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "yTt84lK6jVx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Word2Vec in PySpark\n",
        "wtv = Word2Vec(inputCol='response_tokens', outputCol='model', numPartitions=4)"
      ],
      "metadata": {
        "id": "G_JGgZNM03Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit data\n",
        "model = wtv.fit(rdd_train)"
      ],
      "metadata": {
        "id": "_XX7Npn611oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.getVectors().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBp8ndVf8JVT",
        "outputId": "1cef57c7-05cd-4a02-d005-39b55b5772cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+\n",
            "|         word|              vector|\n",
            "+-------------+--------------------+\n",
            "|    professed|[9.20962076634168...|\n",
            "|    pathogens|[0.05213452130556...|\n",
            "|  advertencia|[-0.0230888389050...|\n",
            "|     quotient|[0.02727679535746...|\n",
            "|     incident|[-0.1272087246179...|\n",
            "|synchronicity|[-0.0107862930744...|\n",
            "|         buns|[-0.0331519544124...|\n",
            "|      serious|[0.07881371676921...|\n",
            "|        brink|[0.03099950402975...|\n",
            "|         9/11|[0.10745714604854...|\n",
            "|      acronym|[-0.0113178882747...|\n",
            "|    foolproof|[0.03159939497709...|\n",
            "|     youthful|[-0.0086543830111...|\n",
            "|     sinister|[0.02207533083856...|\n",
            "|       comply|[0.12050931155681...|\n",
            "|        u0623|[0.07430828362703...|\n",
            "|       breaks|[0.08198492228984...|\n",
            "|        mesmo|[-0.0525239780545...|\n",
            "|    subreddit|[-0.1006804108619...|\n",
            "|          dns|[-0.0173437874764...|\n",
            "+-------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/SIADS 696: Milestone II/Project/Models/initial_pyspark.model')"
      ],
      "metadata": {
        "id": "h9VjvWbc8msf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.transform(rdd_train).head().model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcZMhchl9JQd",
        "outputId": "81f42adb-958d-44d5-90ff-65330d9bc147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([0.0221, -0.0357, -0.1232, -0.0486, -0.1217, 0.0534, -0.2227, -0.1274, -0.066, -0.0054, -0.1524, -0.2124, -0.1227, 0.1874, 0.0208, 0.1111, -0.1775, 0.1581, 0.0088, 0.0062, -0.2181, -0.2011, 0.1006, 0.1279, 0.0911, -0.1285, -0.0128, 0.0132, 0.1514, -0.0339, 0.1665, -0.0664, 0.0891, -0.1419, 0.0577, -0.1358, -0.0763, -0.0473, -0.0999, 0.0603, 0.1182, 0.0541, -0.152, -0.0483, -0.0233, 0.05, -0.0262, 0.2023, 0.0367, -0.0621, 0.0328, 0.0207, -0.1272, -0.056, -0.0632, 0.0667, -0.0892, -0.09, 0.1078, -0.0839, 0.0822, 0.1061, -0.1389, -0.0053, 0.0502, -0.0267, 0.0864, -0.1637, -0.0572, -0.0763, -0.0304, 0.1591, 0.0447, 0.0632, -0.1084, -0.0133, -0.0009, 0.1762, 0.0375, 0.017, 0.0808, -0.0007, 0.0192, -0.0021, 0.0728, -0.1267, -0.1041, -0.0186, -0.0079, 0.0266, -0.0586, 0.1526, -0.0376, 0.0623, 0.0961, -0.153, -0.1867, -0.1506, -0.1198, -0.0786])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Bias"
      ],
      "metadata": {
        "id": "iDMHv9sJjozT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Garg et al. (2018) use a different approach to assess the similarity between a set of neutral words and two groups, first subtracting the distance between each group and a neutral word, then summing the results across words. This approach gives equal weight to each word, unlike the approach below. Documentation is available [here](https://pubmed.ncbi.nlm.nih.gov/29615513/)."
      ],
      "metadata": {
        "id": "VKpcHpdB02X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def add_bias(dataframe, token_column, male_tokens, female_tokens, model):\n",
        "    \"\"\"\n",
        "    Calculate bias scores for text data in a DataFrame based on the difference in distances\n",
        "    from male and female token embeddings.\n",
        "\n",
        "    Parameters:\n",
        "    - dataframe (pd.DataFrame): DataFrame containing the text data.\n",
        "    - token_column (str): Column name containing the lists of tokens.\n",
        "    - male_tokens (list of str): List of tokens associated with male attributes.\n",
        "    - female_tokens (list of str): List of tokens associated with female attributes.\n",
        "    - model: Model with a `get_mean_vector` method to compute embeddings.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame with an additional 'bias' column.\n",
        "    \"\"\"\n",
        "    # Compute embeddings and bias scores directly without intermediate columns\n",
        "    male_vector = model.get_mean_vector(male_tokens)\n",
        "    female_vector = model.get_mean_vector(female_tokens)\n",
        "\n",
        "    def calculate_bias(tokens):\n",
        "        # Ensure the tokens are passed correctly to the model's method\n",
        "        embedding = model.get_mean_vector(tokens)\n",
        "        bias = np.linalg.norm(male_vector - embedding) - np.linalg.norm(female_vector - embedding)\n",
        "        return bias\n",
        "\n",
        "    # Apply the combined operation, ensuring tokens are passed correctly to calculate_bias\n",
        "    dataframe['bias'] = dataframe[token_column].apply(calculate_bias)\n",
        "\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "5TJ_dZdLjp1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_bias(dataframe_train, 'response_text', male_pronouns, female_pronouns, model.wv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dhjX1FjL_JAj",
        "outputId": "507137dd-ad7c-439a-856a-3a674b3c3b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        source   source_id op_gender  \\\n",
              "0          TED     TED5828         W   \n",
              "1          RED   RED906982         M   \n",
              "2          FBW  FBW3327456         W   \n",
              "3          FIT   FIT189959         W   \n",
              "4          RED   RED650418         W   \n",
              "...        ...         ...       ...   \n",
              "3499995    RED   RED382010         M   \n",
              "3499996    FBW  FBW4664155         W   \n",
              "3499997    RED  RED1203857         W   \n",
              "3499998    FIT    FIT21012         M   \n",
              "3499999    RED   RED438653         M   \n",
              "\n",
              "                                             response_text stratify  \\\n",
              "0        Beautiful... If only more people could see thi...     TEDW   \n",
              "1        Idk man. Cubs striking has looked NASTY lately...     REDM   \n",
              "2           Having a hard time right now!! Im right thereüò•     FBWW   \n",
              "3        Welcome! Fitocracy is a great place to track y...     FITW   \n",
              "4        Ich hab Sims4 deinstalliert nachdem ich eine H...     REDW   \n",
              "...                                                    ...      ...   \n",
              "3499995  Bloody sex is the best sex behind Chloroform sex.     REDM   \n",
              "3499996                                           Adorable     FBWW   \n",
              "3499997  I have been to 2 gynecologists.  I have no phy...     REDW   \n",
              "3499998                                          hahaahaah     FITM   \n",
              "3499999                      What about Benjamin Disraeli?     REDM   \n",
              "\n",
              "                                                    tokens      bias  \n",
              "0        [beautiful, ..., if, only, more, people, could... -0.054628  \n",
              "1        [idk, man, ., cubs, striking, has, looked, nas... -0.053548  \n",
              "2        [having, a, hard, time, right, now, !, !, im, ... -0.057289  \n",
              "3        [welcome, !, fitocracy, is, a, great, place, t... -0.052358  \n",
              "4        [ich, hab, sims, 4, deinstalliert, nachdem, ic... -0.053050  \n",
              "...                                                    ...       ...  \n",
              "3499995  [bloody, sex, is, the, best, sex, behind, chlo... -0.054982  \n",
              "3499996                                         [adorable] -0.054897  \n",
              "3499997  [i, have, been, to, 2, gynecologists, ., i, ha... -0.051896  \n",
              "3499998                                        [hahaahaah] -0.045187  \n",
              "3499999               [what, about, benjamin, disraeli, ?] -0.052242  \n",
              "\n",
              "[3499700 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47e21682-842d-45aa-afa0-c87dd8b25766\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_id</th>\n",
              "      <th>op_gender</th>\n",
              "      <th>response_text</th>\n",
              "      <th>stratify</th>\n",
              "      <th>tokens</th>\n",
              "      <th>bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TED</td>\n",
              "      <td>TED5828</td>\n",
              "      <td>W</td>\n",
              "      <td>Beautiful... If only more people could see thi...</td>\n",
              "      <td>TEDW</td>\n",
              "      <td>[beautiful, ..., if, only, more, people, could...</td>\n",
              "      <td>-0.054628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RED</td>\n",
              "      <td>RED906982</td>\n",
              "      <td>M</td>\n",
              "      <td>Idk man. Cubs striking has looked NASTY lately...</td>\n",
              "      <td>REDM</td>\n",
              "      <td>[idk, man, ., cubs, striking, has, looked, nas...</td>\n",
              "      <td>-0.053548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FBW</td>\n",
              "      <td>FBW3327456</td>\n",
              "      <td>W</td>\n",
              "      <td>Having a hard time right now!! Im right thereüò•</td>\n",
              "      <td>FBWW</td>\n",
              "      <td>[having, a, hard, time, right, now, !, !, im, ...</td>\n",
              "      <td>-0.057289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FIT</td>\n",
              "      <td>FIT189959</td>\n",
              "      <td>W</td>\n",
              "      <td>Welcome! Fitocracy is a great place to track y...</td>\n",
              "      <td>FITW</td>\n",
              "      <td>[welcome, !, fitocracy, is, a, great, place, t...</td>\n",
              "      <td>-0.052358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RED</td>\n",
              "      <td>RED650418</td>\n",
              "      <td>W</td>\n",
              "      <td>Ich hab Sims4 deinstalliert nachdem ich eine H...</td>\n",
              "      <td>REDW</td>\n",
              "      <td>[ich, hab, sims, 4, deinstalliert, nachdem, ic...</td>\n",
              "      <td>-0.053050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499995</th>\n",
              "      <td>RED</td>\n",
              "      <td>RED382010</td>\n",
              "      <td>M</td>\n",
              "      <td>Bloody sex is the best sex behind Chloroform sex.</td>\n",
              "      <td>REDM</td>\n",
              "      <td>[bloody, sex, is, the, best, sex, behind, chlo...</td>\n",
              "      <td>-0.054982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499996</th>\n",
              "      <td>FBW</td>\n",
              "      <td>FBW4664155</td>\n",
              "      <td>W</td>\n",
              "      <td>Adorable</td>\n",
              "      <td>FBWW</td>\n",
              "      <td>[adorable]</td>\n",
              "      <td>-0.054897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499997</th>\n",
              "      <td>RED</td>\n",
              "      <td>RED1203857</td>\n",
              "      <td>W</td>\n",
              "      <td>I have been to 2 gynecologists.  I have no phy...</td>\n",
              "      <td>REDW</td>\n",
              "      <td>[i, have, been, to, 2, gynecologists, ., i, ha...</td>\n",
              "      <td>-0.051896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499998</th>\n",
              "      <td>FIT</td>\n",
              "      <td>FIT21012</td>\n",
              "      <td>M</td>\n",
              "      <td>hahaahaah</td>\n",
              "      <td>FITM</td>\n",
              "      <td>[hahaahaah]</td>\n",
              "      <td>-0.045187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3499999</th>\n",
              "      <td>RED</td>\n",
              "      <td>RED438653</td>\n",
              "      <td>M</td>\n",
              "      <td>What about Benjamin Disraeli?</td>\n",
              "      <td>REDM</td>\n",
              "      <td>[what, about, benjamin, disraeli, ?]</td>\n",
              "      <td>-0.052242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3499700 rows √ó 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47e21682-842d-45aa-afa0-c87dd8b25766')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47e21682-842d-45aa-afa0-c87dd8b25766 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47e21682-842d-45aa-afa0-c87dd8b25766');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a2d2ff2b-b9b8-40bb-ba9b-29975bf9f510\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2d2ff2b-b9b8-40bb-ba9b-29975bf9f510')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a2d2ff2b-b9b8-40bb-ba9b-29975bf9f510 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe_train"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function uses Euclidean distance instead of cosine similarity. The advantage of using cosine similarity is that the distance between vectors is normalized. However, because the number of male and female nouns in the HolisticBias dataset is similar, it is not necessary to use a normalized measure, particularly if computational efficiency is compromised. Garg et al. (2018) also use Euclidean distance."
      ],
      "metadata": {
        "id": "v-k8wnWR1CXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reduce Dimensions"
      ],
      "metadata": {
        "id": "IDSoUaWBjskB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_vectorizer(text_data, vectorizer=TfidfVectorizer, tokenizer=TweetTokenizer()):\n",
        "    \"\"\"\n",
        "    Trains a vectorizer on the provided text data and returns the vectorizer instance,\n",
        "    the document-term matrix, and the feature names.\n",
        "\n",
        "    Parameters:\n",
        "    - text_data: List of text documents to be vectorized.\n",
        "    - vectorizer: Vectorizer class to be used for text vectorization. Defaults to CountVectorizer.\n",
        "    - tokenizer: Tokenizer class to be used for tokenizing the text documents. Defaults to TweetTokenizer.\n",
        "\n",
        "    Returns:\n",
        "    - instance: The trained vectorizer instance.\n",
        "    - matrix: The document-term matrix resulting from fitting the vectorizer on `text_data`.\n",
        "    - features: An array of feature names generated by the vectorizer.\n",
        "    \"\"\"\n",
        "    # Initialize the vectorizer with specified configurations\n",
        "    instance = vectorizer(\n",
        "        strip_accents=None,  # Do not strip accents\n",
        "        lowercase=False,  # Do not convert characters to lowercase\n",
        "        tokenizer=tokenizer.tokenize,  # Use the tokenize method of the tokenizer instance\n",
        "        token_pattern=None,  # Since a tokenizer is provided, token_pattern is not used\n",
        "        stop_words=list(stop_words),  # Do not remove stop words\n",
        "        ngram_range=(1, 1),  # Consider only single words (1-grams)\n",
        "        min_df=0.01,  # Minimum document frequency for filtering terms\n",
        "        max_df=0.99,  # Maximum document frequency for filtering terms\n",
        "        max_features=None  # No limit on the number of features\n",
        "    )\n",
        "\n",
        "    # Fit the vectorizer on the provided text data and transform the data into a matrix\n",
        "    matrix = instance.fit_transform(text_data)\n",
        "\n",
        "    # Retrieve the feature names generated by the vectorizer\n",
        "    features = instance.get_feature_names_out()\n",
        "\n",
        "    return instance, matrix, features"
      ],
      "metadata": {
        "id": "j7kfHBD6jr1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svd(matrix, n_components=2, random_state=42):\n",
        "    \"\"\"\n",
        "    Trains a Truncated Singular Value Decomposition (SVD) model on the given matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - matrix: The input matrix to decompose.\n",
        "    - n_components: Number of components to keep.\n",
        "    - random_state: Seed for the random number generator.\n",
        "\n",
        "    Returns:\n",
        "    - A tuple containing the trained SVD model, term-topic matrix, document-topic matrix,\n",
        "      and array of singular values.\n",
        "    \"\"\"\n",
        "    svd = TruncatedSVD(n_components=n_components, random_state=random_state)\n",
        "    model = svd.fit(np.transpose(matrix))\n",
        "    term_topic_matrix = svd.transform(np.transpose(matrix))\n",
        "    document_topic_matrix = svd.components_\n",
        "    singular_values = svd.singular_values_\n",
        "\n",
        "    return model, term_topic_matrix, document_topic_matrix, singular_values"
      ],
      "metadata": {
        "id": "77RZjhK77b20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Data"
      ],
      "metadata": {
        "id": "_0J3OV6jjyjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_hist(dataframe, gender_column='op_gender', bias_column='bias'):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    ax.hist(dataframe[dataframe[gender_column] == 'M'][bias_column], bins=100, density=True, alpha=0.5, label='Original Poster Male')\n",
        "    ax.hist(dataframe[dataframe[gender_column] == 'W'][bias_column], bins=100, density=True, alpha=0.5, label='Original Poster Female')\n",
        "\n",
        "    ax.set_title('Response Bias')\n",
        "    ax.set_xlabel('Calculated Bias')\n",
        "    ax.set_ylabel('Density')\n",
        "    ax.legend()\n",
        "\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "s78lDxk_DBw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_svd(document_topic_matrix, mask):\n",
        "    \"\"\"\n",
        "    Plots the SVD (Singular Value Decomposition) results, separating points by gender based on a mask.\n",
        "\n",
        "    Parameters:\n",
        "    - document_topic_matrix: The document-topic matrix obtained from SVD.\n",
        "    - mask: An array of gender labels ('M' for male, 'W' for female) for each document.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    mask_male = np.where(mask == 'M', True, False)\n",
        "    mask_female = np.where(mask == 'W', True, False)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True, sharey=True, tight_layout=True)\n",
        "\n",
        "    axs[0].scatter(document_topic_matrix[0][mask_male],\n",
        "                   document_topic_matrix[1][mask_male],\n",
        "                   alpha=0.1, color='C0')\n",
        "    axs[0].set_title('Original Poster Male')\n",
        "\n",
        "    axs[1].scatter(document_topic_matrix[0][mask_female],\n",
        "                   document_topic_matrix[1][mask_female],\n",
        "                   alpha=0.1, color='C1')\n",
        "    axs[1].set_title('Original Poster Female')\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.set_xlabel('Principal Component 1')\n",
        "        ax.set_ylabel('Principal Component 2')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2zJvlpm7j4fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "gR1YoCJfqOVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Please annotate the following code and convert it into PEP 8.\" OpenAI. (2023). ChatGPT (Jan 30 version) [Large language model]. https://chat.openai.com/chat\n",
        "\n",
        "Garg, N., Schiebinger, L., Jurafsky, D., & Zou, J. (2018). Word embeddings quantify 100 years of gender and ethnic stereotypes. PNAS, 115(16). https://doi.org/10.1073/pnas.1720347115"
      ],
      "metadata": {
        "id": "Mgokre5XqSXc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rxCqIUxnqXoN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}