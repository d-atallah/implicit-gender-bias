{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-atallah/implicit_gender_bias/blob/main/Supervised_Learning_Dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Steps:\n",
        "\n",
        "*  Test not removing stop words\n",
        "*  Fix Log regression issue\n",
        "  * May be a class imbalance\n",
        "* Score random search on AUC-PR\n",
        "* Use grid search rather than random search in great lakes cluster.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "io7VcWs4weYO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHf_jOR9jOca"
      },
      "source": [
        "# Import, Download, & Variable Statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6WzZ3_ujTwL",
        "outputId": "6b5cbfb4-9fcb-4b3f-9f3d-3ed60420a295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'implicit_gender_bias' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import & download statements\n",
        "# General Statements\n",
        "!git clone https://github.com/d-atallah/implicit_gender_bias.git\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import joblib\n",
        "from implicit_gender_bias import config as cf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Feature selection & Model tuning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.decomposition import TruncatedSVD,PCA, NMF\n",
        "from sklearn.metrics import confusion_matrix,precision_score, recall_score, f1_score, accuracy_score, roc_curve, roc_auc_score, log_loss, make_scorer\n",
        "\n",
        "# Model options\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# NLTK resources\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPZ-eni9oS-A",
        "outputId": "dfe58178-02db-42dc-a443-751c964bb49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Variables\n",
        "# Inputs\n",
        "folder_path = cf.filepath()\n",
        "csv_files = ['facebook_wiki_posts','facebook_wiki_responses','fitocracy_posts','fitocracy_responses','reddit_posts','reddit_responses','ted_responses','facebook_congress_posts','annotations','facebook_congress_responses']\n",
        "\n",
        "annotations = pd.read_csv(folder_path+'annotations_combined.csv')\n",
        "#posts_combined = pd.read_csv(folder_path+'posts_combined.csv')\n",
        "#sources_combined = pd.read_csv(folder_path+'sources_combined_output.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zRF7xFVjBKo"
      },
      "source": [
        "## Define Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3zLj7yI_jJcQ"
      },
      "outputs": [],
      "source": [
        "# Evaluate a model\n",
        "def model_eval(model, X_test, y_test, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluates a specified model using accuracy, precision, recall, F-1 score, AUC, log-Loss, and a confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained model to be evaluated.\n",
        "    - X_test (list or array): Test set features.\n",
        "    - y_test (list or array): True labels.\n",
        "    - y_pred (list or array): Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "    - metrics_df (pd.DataFrame): DataFrame containing the metrics and scores.\n",
        "    - confusion_df (pd.DataFrame): DataFrame containing a confusion matrix.\n",
        "    \"\"\"\n",
        "    # Initialize dataframes\n",
        "    metrics_df = pd.DataFrame(columns=['Metric', 'Score'])\n",
        "    confusion_df = pd.DataFrame(columns=['Actual Positive', 'Actual Negative', 'Predicted Positive', 'Predicted Negative'])\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "                                                      'Score': [accuracy, precision, recall, f1]})])\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['AUC'],\n",
        "                                                      'Score': [auc]})])\n",
        "\n",
        "    logloss = log_loss(y_test, model.predict_proba(X_test))\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['Log-Loss'],\n",
        "                                                      'Score': [logloss]})])\n",
        "\n",
        "    # Reset index\n",
        "    metrics_df = metrics_df.reset_index(drop=True)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    confusion_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "\n",
        "    # Print dataframes\n",
        "    print(\"Metrics:\")\n",
        "    print(metrics_df)\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_df)\n",
        "\n",
        "    return metrics_df, confusion_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "V1jh0q60RcvF"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Applies text preprocessing to a given text, including:\n",
        "    - Removing special characters and digits\n",
        "    - Converting to lowercase\n",
        "    - Tokenization and removing stopwords\n",
        "    - Lemmatization and stemming\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): Input text to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "    - processed_text (str): Preprocessed text after applying the specified steps.\n",
        "    \"\"\"\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenization and removing stopwords\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization and stemming\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    tokens = [porter.stem(word) for word in tokens]\n",
        "\n",
        "    # Rejoin tokens into a processed text\n",
        "    processed_text = ' '.join(tokens)\n",
        "\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a6H7nvVrt_0T"
      },
      "outputs": [],
      "source": [
        "def model_search(X_train, y_train, X_validation, y_validation, X_test, model_type, vectorizer, ngram, search_type, param_grid):\n",
        "  \"\"\"\n",
        "  Searches for the best hyperparameters for a specified model and dimensionality reduction method using GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "  Parameters:\n",
        "  - X_train (array-like): Training set features, preprocessed.\n",
        "  - y_train (array-like): Training set labels.\n",
        "  - X_validation (array-like): Validation set features, preprocessed.\n",
        "  - y_validation (array-like): Validation set labels.\n",
        "  - X_test (array-like): Test set features, preprocessed.\n",
        "  - model_type (str): Type of model to test. Choose from 'log' (Logistic Regression), 'xgb' (XGBoost), or 'rf' (Random Forest).\n",
        "  - vectorizer (str): Type of vectorizer to test. Choose from 'count' (Count Vecotizer) or 'tfidf' (TF-IDF Vecotizer).\n",
        "  - ngram (int): Feature representation to test. Choose 1 for unigrams, 2 for bigrams, and so on.\n",
        "  - search_type (str): Defines grid search or random search style. Choose from 'grid' (Grid Search), 'rand' (Random Search).\n",
        "  - param_grid (dict): Hyperparameter grid for the specified model and dimensionality reduction method.\n",
        "\n",
        "  Returns:\n",
        "  - selected_model: Trained model with the best hyperparameters.\n",
        "  - selected_params (dict): Best hyperparameters found during the search.\n",
        "  - X_train_ (array-like): Vectorized training set features.\n",
        "  - X_validation_ (array-like): Vectorized validation set features.\n",
        "  - X_test_ (array-like): Vectorized test set features.\n",
        "  \"\"\"\n",
        "  if vectorizer == 'count':\n",
        "    vect = CountVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "  elif vectorizer == 'tfidf':\n",
        "    vect = TfidfVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "  else:\n",
        "      raise ValueError(\"Invalid vector type. Use 'count' or 'tfidf'.\")\n",
        "\n",
        "  if model_type == 'log':\n",
        "      model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "  elif model_type == 'xgb':\n",
        "      model = XGBClassifier(random_state=42)\n",
        "  elif model_type == 'rf':\n",
        "      model = RandomForestClassifier(random_state=42)\n",
        "  else:\n",
        "      raise ValueError(\"Invalid model type. Use 'xgb', 'rf', or 'log'.\")\n",
        "\n",
        "  # Pipeline with dimensionality reduction method and model to test\n",
        "  #Chose SVD ad reduction method because the data is sparse (PCA and NMF not applicable)\n",
        "  pipeline = make_pipeline(\n",
        "    TruncatedSVD(random_state=42),\n",
        "    model\n",
        "  )\n",
        "\n",
        "  # Cross-validation StratifiedKFold for classification (Reduce risk of overfitting )\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "  if search_type == 'grid':\n",
        "    # Use F1-score as the scoring metric in GridSearchCV (This can be changed to any other metric)\n",
        "\n",
        "    search = GridSearchCV(\n",
        "        pipeline, param_grid, cv=cv, scoring=make_scorer(f1_score), n_jobs=-1, random_state=42\n",
        "    )\n",
        "    # Fit the grid search to the data\n",
        "    search.fit(X_train_, y_train)\n",
        "\n",
        "  elif search_type == 'random':\n",
        "\n",
        "    # Use F1-score as the scoring metric in RandomizedSearchCV\n",
        "    search = RandomizedSearchCV(\n",
        "      pipeline, param_distributions=param_grid, cv=cv, scoring='f1', n_iter=10, n_jobs=-1, random_state=42\n",
        "    )\n",
        "    # Fit random search to the data\n",
        "    search.fit(X_train_, y_train)\n",
        "\n",
        "  else:\n",
        "    raise ValueError(\"Invalid search type. Use 'grid' or 'random'.\")\n",
        "\n",
        "  # Get best parameters\n",
        "  selected_params = search.best_params_\n",
        "  print(f\"Hyperparameters:\", selected_params)\n",
        "\n",
        "  # Train a new model with the best hyperparameters\n",
        "  selected_model = search.best_estimator_\n",
        "\n",
        "  # Evaluate the model on the validation set\n",
        "  y_val_pred = selected_model.predict(X_validation_)\n",
        "  metrics_val_df, confusion_val_df = model_eval(selected_model, X_validation_, y_validation, y_val_pred)\n",
        "\n",
        "  return selected_model, selected_params, X_train_, X_validation_, X_test_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OZmlCPsrWD6"
      },
      "source": [
        "# Train, Validate, Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PlNBS5XIrOBP"
      },
      "outputs": [],
      "source": [
        "# Annotation only\n",
        "# Set train-test split variables\n",
        "X = annotations['response_text']\n",
        "y = annotations['op_gender_binary']\n",
        "\n",
        "# Perform stratified train-test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Then, split the temp set into validation and test sets\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hlRU05nrUOB"
      },
      "outputs": [],
      "source": [
        "# All responses combined\n",
        "# Set train-test split variables\n",
        "X = responses_combined['response_text']\n",
        "y = responses_combined['op_gender_binary']\n",
        "\n",
        "# Perform stratified train-test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=responses_combined['source']\n",
        ")\n",
        "\n",
        "# Then, split the temp set into validation and test sets\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=responses_combined['source']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kRKA5ev5QbwY"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to each set (X_train, X_validation, X_test)\n",
        "X_train_preprocessed = X_train.apply(preprocess_text)\n",
        "X_validation_preprocessed = X_validation.apply(preprocess_text)\n",
        "X_test_preprocessed = X_test.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsUhDyhs-EK"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pdIbADLEKghY"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "  'truncatedsvd__n_components': [150, 200, 250],  # Number of components to keep after dimensionality reduction using Truncated SVD\n",
        "  'xgbclassifier__n_estimators': [50, 100, 150],  # Number of boosting rounds (trees) in the XGBoost model\n",
        "  'xgbclassifier__max_depth': [3, 5, 7],  # Maximum depth of each tree in the XGBoost model\n",
        "  'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage used in boosting (controls the learning rate)\n",
        "  'xgbclassifier__subsample': [0.8, 1.0],  # Fraction of samples used for training each tree (subsample ratio)\n",
        "  'xgbclassifier__colsample_bytree':  [0.8, 1.0],  # Fraction of features used for training each tree (column subsampling ratio)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a test based on random search (Will implement in near future)"
      ],
      "metadata": {
        "id": "cXbPqnSnxPMH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6YFhazFMPdd"
      },
      "outputs": [],
      "source": [
        "enhanced_param_grid = {\n",
        "  'truncatedsvd__n_components': [150, 175, 200, 225, 250],  # Enhanced range for the number of components in Truncated SVD\n",
        "  'xgbclassifier__n_estimators': [30, 50, 70],  # Enhanced range for the number of boosting rounds in XGBoost\n",
        "  'xgbclassifier__max_depth': [2, 3, 4],  # Enhanced range for the maximum depth of each tree in XGBoost\n",
        "  'xgbclassifier__learning_rate': [0.005, 0.01, 0.05, 0.1, 0.15],  # Enhanced range for the learning rate in XGBoost\n",
        "  'xgbclassifier__subsample': [0.5, 0.6, 0.8],  # Enhanced range for the subsample ratio in XGBoost\n",
        "  'xgbclassifier__colsample_bytree':  [0.5, 0.6, 0.8],  # Enhanced range for the column subsampling ratio in XGBoost\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH9ckPz9pD8f"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV1E1he5pHAE",
        "outputId": "2e845e25-7bb8-48f1-9a67-748994322e7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 50, 'xgbclassifier__max_depth': 3, 'xgbclassifier__learning_rate': 0.01, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 200}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.533884\n",
            "1  Precision  0.531361\n",
            "2     Recall  0.761662\n",
            "3   F1-Score  0.626002\n",
            "4        AUC  0.528204\n",
            "5   Log-Loss  0.691006\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 331                 792\n",
            "Actual Negative                 281                 898\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TdizZApp6cd"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DTIzS8OqH7N",
        "outputId": "47a08fc2-f247-4fbf-f7da-7a91913a5e16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 50, 'xgbclassifier__max_depth': 3, 'xgbclassifier__learning_rate': 0.01, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 200}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.538662\n",
            "1  Precision  0.532810\n",
            "2     Recall  0.805768\n",
            "3   F1-Score  0.641458\n",
            "4        AUC  0.532002\n",
            "5   Log-Loss  0.690338\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 290                 833\n",
            "Actual Negative                 229                 950\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhBhjmG9Q-PA"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtTDMLYNaL9Z",
        "outputId": "5e8f1dae-8c0c-448f-b664-9c44b8b1671e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 50, 'xgbclassifier__max_depth': 3, 'xgbclassifier__learning_rate': 0.01, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 200}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.517811\n",
            "1  Precision  0.515935\n",
            "2     Recall  0.947413\n",
            "3   F1-Score  0.668062\n",
            "4        AUC  0.507099\n",
            "5   Log-Loss  0.692302\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                  75                1048\n",
            "Actual Negative                  62                1117\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYVeJ-fLUGYk"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIPSMHCZUF3S",
        "outputId": "f41826a0-2717-4f8a-ad1e-bc11918c6e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 50, 'xgbclassifier__max_depth': 3, 'xgbclassifier__learning_rate': 0.01, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 200}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.517376\n",
            "1  Precision  0.517400\n",
            "2     Recall  0.857506\n",
            "3   F1-Score  0.645388\n",
            "4        AUC  0.508896\n",
            "5   Log-Loss  0.692628\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 180                 943\n",
            "Actual Negative                 168                1011\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "322iMKuvi26V"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idMBuw6KLJPa"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'logisticregression__solver': ['saga'],\n",
        "    'logisticregression__penalty': ['l1', 'l2'],\n",
        "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Adjust the range based on the characteristics of your data\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FLV_drUIqJ4"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHFIZlGSIp1d",
        "outputId": "30b4b2f6-59f4-4ec4-91e4-f74e03691297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l1', 'logisticregression__C': 0.01}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.512163\n",
            "1  Precision  0.512163\n",
            "2     Recall  1.000000\n",
            "3   F1-Score  0.677392\n",
            "4        AUC  0.500000\n",
            "5   Log-Loss  0.692876\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                   0                1123\n",
            "Actual Negative                   0                1179\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TRehJnsIqND"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky6HH6pyIpxN",
        "outputId": "9d94d166-c148-4f74-abac-44e582f9165a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l1', 'logisticregression__C': 0.01}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.512163\n",
            "1  Precision  0.512163\n",
            "2     Recall  1.000000\n",
            "3   F1-Score  0.677392\n",
            "4        AUC  0.500000\n",
            "5   Log-Loss  0.694080\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                   0                1123\n",
            "Actual Negative                   0                1179\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-M2YnogoaaF"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh7MahEdIl3f",
        "outputId": "40290c60-8f07-4a86-af39-ca5ede765e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'liblinear', 'logisticregression__penalty': 'l1', 'logisticregression__C': 0.1}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.512163\n",
            "1  Precision  0.512163\n",
            "2     Recall  1.000000\n",
            "3   F1-Score  0.677392\n",
            "4        AUC  0.500000\n",
            "5   Log-Loss  0.692893\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                   0                1123\n",
            "Actual Negative                   0                1179\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zen4PB78Hwon"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DogxZmvd-bnP",
        "outputId": "5bc45743-52cb-4114-910e-466c8177a9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'liblinear', 'logisticregression__penalty': 'l1', 'logisticregression__C': 0.1}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.512163\n",
            "1  Precision  0.512163\n",
            "2     Recall  1.000000\n",
            "3   F1-Score  0.677392\n",
            "4        AUC  0.500000\n",
            "5   Log-Loss  0.692893\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                   0                1123\n",
            "Actual Negative                   0                1179\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdKBq7ETihSJ"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JN7diHaUK4sh"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'truncatedsvd__n_components': [150, 200, 250],  # Number of components to keep after dimensionality reduction using Truncated SVD\n",
        "    'randomforestclassifier__n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=10)],  # Number of trees in the forest\n",
        "    'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at every split\n",
        "    'randomforestclassifier__max_depth': [int(x) for x in np.linspace(10, 110, num=11)],  # Maximum depth of the tree\n",
        "    'randomforestclassifier__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "    'randomforestclassifier__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
        "    'randomforestclassifier__bootstrap': [True, False]  # Method of selecting samples for training each tree\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-IjvxnzJRIs"
      },
      "source": [
        "### Random Forest Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgo5suaYJQtN",
        "outputId": "4084ddad-07e7-422f-bd97-f5280337d0dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'truncatedsvd__n_components': 200, 'randomforestclassifier__n_estimators': 1800, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__max_depth': 80, 'randomforestclassifier__bootstrap': True}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.567333\n",
            "1  Precision  0.566161\n",
            "2     Recall  0.664122\n",
            "3   F1-Score  0.611241\n",
            "4        AUC  0.564919\n",
            "5   Log-Loss  0.666130\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 523                 600\n",
            "Actual Negative                 396                 783\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'rf'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "rf_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU5wDIxbJQ8C"
      },
      "source": [
        "### Random Forest Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsLCJbmJJQou"
      },
      "outputs": [],
      "source": [
        "# Define variables\n",
        "model = 'rf'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "rf_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8gaKVETJQ0Q"
      },
      "source": [
        "### Random Forest Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4pkI77HJQeE"
      },
      "outputs": [],
      "source": [
        "# Define variables\n",
        "model = 'rf'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "rf_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FtabLhhJQ2x"
      },
      "source": [
        "### Random Forest Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2ncMEpAJQbg"
      },
      "outputs": [],
      "source": [
        "# Define variables\n",
        "model = 'rf'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid)\n",
        "\n",
        "# Save results to dictionary\n",
        "rf_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpXbxovwpwhV"
      },
      "source": [
        "# Evaluate model on test set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeuLUrWJOEed"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "y_test_pred = xgb_svd_model.predict(X_test_vcount_bi)\n",
        "metrics_test_df, confusion_test_df = model_eval(xgb_svd_model, X_test_vcount_bi, y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcVKm1Lf8UMY"
      },
      "source": [
        "# Write best model and data to shared drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "attu5aSwi0cS"
      },
      "outputs": [],
      "source": [
        "# Save the vectorizer and associated data\n",
        "joblib.dump(vectorizer_tfidf_bi,folder_path+'tfidf_vectorizer_bi.pkl')\n",
        "joblib.dump(X_train_vtfidf_bi, folder_path+'X_train_vtfidf_bi.pkl')\n",
        "joblib.dump(X_validation_vtfidf_bi, folder_path+'X_validation_vtfidf_bi.pkl')\n",
        "joblib.dump(X_test_vtfidf_bi, folder_path+'X_test_vtfidf_bi.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKVmXpvLtjHtKIvmqk/Ov5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}