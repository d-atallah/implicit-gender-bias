{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-atallah/implicit_gender_bias/blob/main/Supervised_Learning_Dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Steps:\n",
        "\n",
        "*  Test not removing stop words\n",
        "*  Fix Log regression issue\n",
        "  * May be a class imbalance - Checked into this and found no imbalance. I tried scoring on AUC-PR and the model results were better but still not great. I believe a logistic regression may be to simple of a model to work with our data.\n",
        "* Score random search on AUC-PR\n",
        "  * Log regression performance was enhanced by AUC-PR score. I am now testing the best xgb model using AUC-PR. On great lakes I am running the last two random forest models.\n",
        "* Use grid search rather than random search in great lakes cluster.\n",
        "\n",
        "* Once I get the auc-pr tested XGB I will save results and try removing the stop word removal and rescore the XGB model. Once I have the best of those results I will work on using grid search with a narrowed down search range. I will do that step in great lakes for efficiency.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "io7VcWs4weYO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHf_jOR9jOca"
      },
      "source": [
        "# Import, Download, & Variable Statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6WzZ3_ujTwL",
        "outputId": "5155469d-6a35-4835-d3bf-b982720909af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'implicit_gender_bias' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import & download statements\n",
        "# General Statements\n",
        "!git clone https://github.com/d-atallah/implicit_gender_bias.git\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import joblib\n",
        "from implicit_gender_bias import config as cf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Feature selection & Model tuning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.decomposition import TruncatedSVD,PCA, NMF\n",
        "from sklearn.metrics import confusion_matrix,precision_score, recall_score, f1_score, accuracy_score, roc_curve, roc_auc_score, log_loss, make_scorer, average_precision_score\n",
        "\n",
        "# Model options\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# NLTK resources\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPZ-eni9oS-A",
        "outputId": "7601f13f-a6c7-4ce5-e631-48888d597a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Variables\n",
        "# Inputs\n",
        "folder_path = cf.filepath() #'/home/gibsonce/datallah-jaymefis-gibsonce/'\n",
        "csv_files = ['facebook_wiki_posts','facebook_wiki_responses','fitocracy_posts','fitocracy_responses','reddit_posts','reddit_responses','ted_responses','facebook_congress_posts','annotations','facebook_congress_responses']\n",
        "\n",
        "annotations = pd.read_csv(folder_path+'annotations_combined.csv')\n",
        "#posts_combined = pd.read_csv(folder_path+'posts_combined.csv')\n",
        "#sources_combined = pd.read_csv(folder_path+'sources_combined_output.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zRF7xFVjBKo"
      },
      "source": [
        "## Define Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3zLj7yI_jJcQ"
      },
      "outputs": [],
      "source": [
        "# Evaluate a model\n",
        "def model_eval(model, X_test, y_test, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluates a specified model using accuracy, precision, recall, F-1 score, AUC, log-Loss, and a confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained model to be evaluated.\n",
        "    - X_test (list or array): Test set features.\n",
        "    - y_test (list or array): True labels.\n",
        "    - y_pred (list or array): Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "    - metrics_df (pd.DataFrame): DataFrame containing the metrics and scores.\n",
        "    - confusion_df (pd.DataFrame): DataFrame containing a confusion matrix.\n",
        "    \"\"\"\n",
        "    # Initialize dataframes\n",
        "    metrics_df = pd.DataFrame(columns=['Metric', 'Score'])\n",
        "    confusion_df = pd.DataFrame(columns=['Actual Positive', 'Actual Negative', 'Predicted Positive', 'Predicted Negative'])\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "                                                      'Score': [accuracy, precision, recall, f1]})])\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['AUC'],\n",
        "                                                      'Score': [auc]})])\n",
        "\n",
        "    logloss = log_loss(y_test, model.predict_proba(X_test))\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['Log-Loss'],\n",
        "                                                      'Score': [logloss]})])\n",
        "\n",
        "    # Reset index\n",
        "    metrics_df = metrics_df.reset_index(drop=True)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    confusion_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "\n",
        "    # Print dataframes\n",
        "    print(\"Metrics:\")\n",
        "    print(metrics_df)\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_df)\n",
        "\n",
        "    return metrics_df, confusion_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = {'a',\n",
        " 'about',\n",
        " 'above',\n",
        " 'after',\n",
        " 'again',\n",
        " 'against',\n",
        " 'ain',\n",
        " 'all',\n",
        " 'am',\n",
        " 'an',\n",
        " 'and',\n",
        " 'any',\n",
        " 'are',\n",
        " 'aren',\n",
        " \"aren't\",\n",
        " 'as',\n",
        " 'at',\n",
        " 'be',\n",
        " 'because',\n",
        " 'been',\n",
        " 'before',\n",
        " 'being',\n",
        " 'below',\n",
        " 'between',\n",
        " 'both',\n",
        " 'but',\n",
        " 'by',\n",
        " 'can',\n",
        " 'couldn',\n",
        " \"couldn't\",\n",
        " 'd',\n",
        " 'did',\n",
        " 'didn',\n",
        " \"didn't\",\n",
        " 'do',\n",
        " 'does',\n",
        " 'doesn',\n",
        " \"doesn't\",\n",
        " 'doing',\n",
        " 'don',\n",
        " \"don't\",\n",
        " 'down',\n",
        " 'during',\n",
        " 'each',\n",
        " 'few',\n",
        " 'for',\n",
        " 'from',\n",
        " 'further',\n",
        " 'had',\n",
        " 'hadn',\n",
        " \"hadn't\",\n",
        " 'has',\n",
        " 'hasn',\n",
        " \"hasn't\",\n",
        " 'have',\n",
        " 'haven',\n",
        " \"haven't\",\n",
        " 'having',\n",
        " #'he',\n",
        " #'her',\n",
        " 'here',\n",
        " #'hers',\n",
        " #'herself',\n",
        " #'him',\n",
        " #'himself',\n",
        " #'his',\n",
        " 'how',\n",
        " 'i',\n",
        " 'if',\n",
        " 'in',\n",
        " 'into',\n",
        " 'is',\n",
        " 'isn',\n",
        " \"isn't\",\n",
        " 'it',\n",
        " \"it's\",\n",
        " 'its',\n",
        " 'itself',\n",
        " 'just',\n",
        " 'll',\n",
        " 'm',\n",
        " 'ma',\n",
        " 'me',\n",
        " 'mightn',\n",
        " \"mightn't\",\n",
        " 'more',\n",
        " 'most',\n",
        " 'mustn',\n",
        " \"mustn't\",\n",
        " 'my',\n",
        " 'myself',\n",
        " 'needn',\n",
        " \"needn't\",\n",
        " 'no',\n",
        " 'nor',\n",
        " 'not',\n",
        " 'now',\n",
        " 'o',\n",
        " 'of',\n",
        " 'off',\n",
        " 'on',\n",
        " 'once',\n",
        " 'only',\n",
        " 'or',\n",
        " 'other',\n",
        " 'our',\n",
        " 'ours',\n",
        " 'ourselves',\n",
        " 'out',\n",
        " 'over',\n",
        " 'own',\n",
        " 're',\n",
        " 's',\n",
        " 'same',\n",
        " 'shan',\n",
        " \"shan't\",\n",
        " #'she',\n",
        " #\"she's\",\n",
        " 'should',\n",
        " \"should've\",\n",
        " 'shouldn',\n",
        " \"shouldn't\",\n",
        " 'so',\n",
        " 'some',\n",
        " 'such',\n",
        " 't',\n",
        " 'than',\n",
        " 'that',\n",
        " \"that'll\",\n",
        " 'the',\n",
        " 'their',\n",
        " 'theirs',\n",
        " 'them',\n",
        " 'themselves',\n",
        " 'then',\n",
        " 'there',\n",
        " 'these',\n",
        " 'they',\n",
        " 'this',\n",
        " 'those',\n",
        " 'through',\n",
        " 'to',\n",
        " 'too',\n",
        " 'under',\n",
        " 'until',\n",
        " 'up',\n",
        " 've',\n",
        " 'very',\n",
        " 'was',\n",
        " 'wasn',\n",
        " \"wasn't\",\n",
        " 'we',\n",
        " 'were',\n",
        " 'weren',\n",
        " \"weren't\",\n",
        " 'what',\n",
        " 'when',\n",
        " 'where',\n",
        " 'which',\n",
        " 'while',\n",
        " 'who',\n",
        " 'whom',\n",
        " 'why',\n",
        " 'will',\n",
        " 'with',\n",
        " 'won',\n",
        " \"won't\",\n",
        " 'wouldn',\n",
        " \"wouldn't\",\n",
        " 'y',\n",
        " 'you',\n",
        " \"you'd\",\n",
        " \"you'll\",\n",
        " \"you're\",\n",
        " \"you've\",\n",
        " 'your',\n",
        " 'yours',\n",
        " 'yourself',\n",
        " 'yourselves'}"
      ],
      "metadata": {
        "id": "pscLi2HiU1CL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "V1jh0q60RcvF"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Applies text preprocessing to a given text, including:\n",
        "    - Removing special characters and digits\n",
        "    - Converting to lowercase\n",
        "    - Tokenization and removing stopwords\n",
        "    - Lemmatization and stemming\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): Input text to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "    - processed_text (str): Preprocessed text after applying the specified steps.\n",
        "    \"\"\"\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenization and removing stopwords\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization and stemming\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    tokens = [porter.stem(word) for word in tokens]\n",
        "\n",
        "    # Rejoin tokens into a processed text\n",
        "    processed_text = ' '.join(tokens)\n",
        "\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "a6H7nvVrt_0T"
      },
      "outputs": [],
      "source": [
        "def model_search(X_train, y_train, X_validation, y_validation, X_test, model_type, vectorizer, ngram, search_type, param_grid, metric_score):\n",
        "  \"\"\"\n",
        "  Searches for the best hyperparameters for a specified model and dimensionality reduction method using GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "  Parameters:\n",
        "  - X_train (array-like): Training set features, preprocessed.\n",
        "  - y_train (array-like): Training set labels.\n",
        "  - X_validation (array-like): Validation set features, preprocessed.\n",
        "  - y_validation (array-like): Validation set labels.\n",
        "  - X_test (array-like): Test set features, preprocessed.\n",
        "  - model_type (str): Type of model to test. Choose from 'log' (Logistic Regression), 'xgb' (XGBoost), or 'rf' (Random Forest), 'knn' ().\n",
        "  - vectorizer (str): Type of vectorizer to test. Choose from 'count' (Count Vecotizer) or 'tfidf' (TF-IDF Vecotizer).\n",
        "  - ngram (int): Feature representation to test. Choose 1 for unigrams, 2 for bigrams, and so on.\n",
        "  - search_type (str): Defines grid search or random search style. Choose from 'grid' (Grid Search), 'rand' (Random Search).\n",
        "  - param_grid (dict): Hyperparameter grid for the specified model and dimensionality reduction method.\n",
        "  - metric_score (str): Defines metric to score search on. Choose from 'f1' (F-1), 'auc-pr' (area under the precision-recall curve). *We can add more options if needed.\n",
        "\n",
        "  Returns:\n",
        "  - selected_model: Trained model with the best hyperparameters.\n",
        "  - selected_params (dict): Best hyperparameters found during the search.\n",
        "  - X_train_ (array-like): Vectorized training set features.\n",
        "  - X_validation_ (array-like): Vectorized validation set features.\n",
        "  - X_test_ (array-like): Vectorized test set features.\n",
        "  \"\"\"\n",
        "  if vectorizer == 'count':\n",
        "    vect = CountVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "  elif vectorizer == 'tfidf':\n",
        "    vect = TfidfVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "  else:\n",
        "      raise ValueError(\"Invalid vector type. Use 'count' or 'tfidf'.\")\n",
        "\n",
        "  if model_type == 'log':\n",
        "      model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "  elif model_type == 'xgb':\n",
        "      model = XGBClassifier(random_state=42)\n",
        "  elif model_type == 'rf':\n",
        "      model = RandomForestClassifier(random_state=42)\n",
        "  else:\n",
        "      raise ValueError(\"Invalid model type. Use 'xgb', 'rf', or 'log'.\")\n",
        "\n",
        "  # Pipeline with dimensionality reduction method and model to test\n",
        "  #Chose SVD ad reduction method because the data is sparse (PCA and NMF not applicable)\n",
        "  pipeline = make_pipeline(\n",
        "    TruncatedSVD(random_state=42),\n",
        "    model\n",
        "  )\n",
        "\n",
        "  # Cross-validation StratifiedKFold for classification (Reduce risk of overfitting )\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "  if metric_score == 'f1':\n",
        "    scorer = make_scorer(f1_score)\n",
        "  elif metric_score == 'auc-pr':\n",
        "    scorer = make_scorer(average_precision_score)\n",
        "\n",
        "  if search_type == 'grid':\n",
        "    # Use F1-score as the scoring metric in GridSearchCV (This can be changed to any other metric)\n",
        "\n",
        "    search = GridSearchCV(\n",
        "        pipeline, param_grid, cv=cv, scoring=scorer, n_jobs=-1, random_state=42\n",
        "    )\n",
        "    # Fit the grid search to the data\n",
        "    search.fit(X_train_, y_train)\n",
        "\n",
        "  elif search_type == 'random':\n",
        "\n",
        "    # Use F1-score as the scoring metric in RandomizedSearchCV\n",
        "    search = RandomizedSearchCV(\n",
        "      pipeline, param_distributions=param_grid, cv=cv, scoring=scorer, n_iter=10, n_jobs=-1, random_state=42\n",
        "    )\n",
        "    # Fit random search to the data\n",
        "    search.fit(X_train_, y_train)\n",
        "\n",
        "  else:\n",
        "    raise ValueError(\"Invalid search type. Use 'grid' or 'random'.\")\n",
        "\n",
        "  # Get best parameters\n",
        "  selected_params = search.best_params_\n",
        "  print(f\"Hyperparameters:\", selected_params)\n",
        "\n",
        "  # Train a new model with the best hyperparameters\n",
        "  selected_model = search.best_estimator_\n",
        "\n",
        "  # Evaluate the model on the validation set\n",
        "  y_val_pred = selected_model.predict(X_validation_)\n",
        "  metrics_val_df, confusion_val_df = model_eval(selected_model, X_validation_, y_validation, y_val_pred)\n",
        "\n",
        "  return selected_model, selected_params, X_train_, X_validation_, X_test_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def model_search(X_train, y_train, X_validation, y_validation, X_test, model_type, vectorizer, ngram, search_type, param_grid, metric_score):\n",
        "  \"\"\"\n",
        "  Searches for the best hyperparameters for a specified model and dimensionality reduction method using GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "  Parameters:\n",
        "  - X_train (array-like): Training set features, preprocessed.\n",
        "  - y_train (array-like): Training set labels.\n",
        "  - X_validation (array-like): Validation set features, preprocessed.\n",
        "  - y_validation (array-like): Validation set labels.\n",
        "  - X_test (array-like): Test set features, preprocessed.\n",
        "  - model_type (str): Type of model to test. Choose from 'log' (Logistic Regression), 'xgb' (XGBoost), or 'rf' (Random Forest), 'knn' (k-Nearest Neighbors), 'svm' (Support Vector Machine).\n",
        "  - vectorizer (str): Type of vectorizer to test. Choose from 'count' (Count Vecotizer) or 'tfidf' (TF-IDF Vecotizer).\n",
        "  - ngram (int): Feature representation to test. Choose 1 for unigrams, 2 for bigrams, and so on.\n",
        "  - search_type (str): Defines grid search or random search style. Choose from 'grid' (Grid Search), 'rand' (Random Search).\n",
        "  - param_grid (dict): Hyperparameter grid for the specified model and dimensionality reduction method.\n",
        "  - metric_score (str): Defines metric to score search on. Choose from 'f1' (F-1), 'auc-pr' (area under the precision-recall curve). *We can add more options if needed.\n",
        "\n",
        "  Returns:\n",
        "  - selected_model: Trained model with the best hyperparameters.\n",
        "  - selected_params (dict): Best hyperparameters found during the search.\n",
        "  - X_train_ (array-like): Vectorized training set features.\n",
        "  - X_validation_ (array-like): Vectorized validation set features.\n",
        "  - X_test_ (array-like): Vectorized test set features.\n",
        "  \"\"\"\n",
        "  if vectorizer == 'count':\n",
        "    vect = CountVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "  elif vectorizer == 'tfidf':\n",
        "    vect = TfidfVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "  else:\n",
        "      raise ValueError(\"Invalid vector type. Use 'count' or 'tfidf'.\")\n",
        "\n",
        "  if model_type == 'log':\n",
        "      model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "  elif model_type == 'xgb':\n",
        "      model = XGBClassifier(random_state=42)\n",
        "  elif model_type == 'rf':\n",
        "      model = RandomForestClassifier(random_state=42)\n",
        "  elif model_type == 'knn':\n",
        "      model = KNeighborsClassifier()\n",
        "  elif model_type == 'svm':\n",
        "      model =  SVC(probability=True)\n",
        "  else:\n",
        "      raise ValueError(\"Invalid model type. Use 'xgb', 'rf', 'svm', 'knn', or 'log'.\")\n",
        "\n",
        "  # Pipeline with dimensionality reduction method and model to test\n",
        "  #Chose SVD ad reduction method because the data is sparse (PCA and NMF not applicable)\n",
        "  pipeline = make_pipeline(\n",
        "    TruncatedSVD(random_state=42),\n",
        "    model\n",
        "  )\n",
        "\n",
        "  # Cross-validation StratifiedKFold for classification (Reduce risk of overfitting )\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "  if metric_score == 'f1':\n",
        "    scorer = make_scorer(f1_score)\n",
        "  elif metric_score == 'auc-pr':\n",
        "    scorer = make_scorer(average_precision_score)\n",
        "\n",
        "  if search_type == 'grid':\n",
        "    # Use F1-score as the scoring metric in GridSearchCV (This can be changed to any other metric)\n",
        "\n",
        "    search = GridSearchCV(\n",
        "        pipeline, param_grid, cv=cv, scoring=scorer, n_jobs=-1, random_state=42\n",
        "    )\n",
        "    # Fit the grid search to the data\n",
        "    search.fit(X_train_, y_train)\n",
        "\n",
        "  elif search_type == 'random':\n",
        "\n",
        "    # Use F1-score as the scoring metric in RandomizedSearchCV\n",
        "    search = RandomizedSearchCV(\n",
        "      pipeline, param_distributions=param_grid, cv=cv, scoring=scorer, n_iter=10, n_jobs=-1, random_state=42\n",
        "    )\n",
        "    # Fit random search to the data\n",
        "    search.fit(X_train_, y_train)\n",
        "\n",
        "  else:\n",
        "    raise ValueError(\"Invalid search type. Use 'grid' or 'random'.\")\n",
        "\n",
        "  # Get best parameters\n",
        "  selected_params = search.best_params_\n",
        "  print(f\"Hyperparameters:\", selected_params)\n",
        "\n",
        "  # Train a new model with the best hyperparameters\n",
        "  selected_model = search.best_estimator_\n",
        "\n",
        "  # Evaluate the model on the validation set\n",
        "  y_val_pred = selected_model.predict(X_validation_)\n",
        "  metrics_val_df, confusion_val_df = model_eval(selected_model, X_validation_, y_validation, y_val_pred)\n",
        "\n",
        "  return selected_model, selected_params, X_train_, X_validation_, X_test_, metrics_val_df"
      ],
      "metadata": {
        "id": "leBXV_yJb04G"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_rank(models_list, model_str, metric, ascending=False):\n",
        "    \"\"\"\n",
        "    Finds the model with the best score based on a specified metric.\n",
        "\n",
        "    Parameters:\n",
        "    - models_list (list): List of dictionaries, each representing a model's details.\n",
        "    - model_str (list): List of model names corresponding to models_list.\n",
        "    - metric (str): Metric to rank the models by (e.g., 'Accuracy', 'F1-Score').\n",
        "    - ascending (bool): Whether to sort in ascending order (default is True).\n",
        "\n",
        "    Returns:\n",
        "    - sorted_metrics_df: DataFrame of models sorted by the best score for the specified metric.\n",
        "    \"\"\"\n",
        "    # Extract 'metrics' from each dictionary and create a DataFrame\n",
        "    all_metrics = [model['metrics'] for model in models_list]\n",
        "    all_metrics_df = pd.concat(all_metrics, keys=model_str, names=['model_name'])\n",
        "\n",
        "    # Sort the DataFrame based on the specified metric\n",
        "    sorted_metrics_df = all_metrics_df[all_metrics_df['Metric'] == metric].sort_values(by='Score', ascending=ascending)\n",
        "\n",
        "    # Reset the index to get the model names\n",
        "    sorted_metrics_df.reset_index(inplace=True)\n",
        "    sorted_metrics_df.drop('level_1', axis=1, inplace=True)\n",
        "\n",
        "    return sorted_metrics_df"
      ],
      "metadata": {
        "id": "bZ9IeKzIkjZx"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OZmlCPsrWD6"
      },
      "source": [
        "# Train, Validate, Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PlNBS5XIrOBP"
      },
      "outputs": [],
      "source": [
        "# Annotation only\n",
        "# Set train-test split variables\n",
        "X = annotations['response_text']\n",
        "y = annotations['op_gender_binary']\n",
        "\n",
        "# Perform stratified train-test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Then, split the temp set into validation and test sets\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hlRU05nrUOB"
      },
      "outputs": [],
      "source": [
        "# All responses combined\n",
        "# Set train-test split variables\n",
        "#X = responses_combined['response_text']\n",
        "#y = responses_combined['op_gender_binary']\n",
        "\n",
        "# Perform stratified train-test split\n",
        "#X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "#    X, y, test_size=0.3, random_state=42, stratify=responses_combined['source']\n",
        "#)\n",
        "\n",
        "# Then, split the temp set into validation and test sets\n",
        "#X_validation, X_test, y_validation, y_test = train_test_split(\n",
        "#    X_temp, y_temp, test_size=0.5, random_state=42, stratify=responses_combined['source']\n",
        "#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kRKA5ev5QbwY"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to each set (X_train, X_validation, X_test)\n",
        "X_train_preprocessed = X_train.apply(preprocess_text)\n",
        "X_validation_preprocessed = X_validation.apply(preprocess_text)\n",
        "X_test_preprocessed = X_test.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for class imbalance:"
      ],
      "metadata": {
        "id": "0TLh5IitPSwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_distribution = pd.Series(y_train).value_counts()\n",
        "class_distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOundgQTOvwp",
        "outputId": "6431852b-7612-46b3-f7bd-8415424034f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5464\n",
              "0    5281\n",
              "Name: op_gender_binary, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsUhDyhs-EK"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "pdIbADLEKghY"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "  'truncatedsvd__n_components': [150, 200, 250],              # Number of components to keep after dimensionality reduction using Truncated SVD\n",
        "  'xgbclassifier__n_estimators': [50, 100, 150],              # Number of boosting rounds (trees) in the XGBoost model\n",
        "  'xgbclassifier__max_depth': [3, 5, 7],                      # Maximum depth of each tree in the XGBoost model\n",
        "  'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],           # Step size shrinkage used in boosting (controls the learning rate)\n",
        "  'xgbclassifier__subsample': [0.8, 1.0],                     # Fraction of samples used for training each tree (subsample ratio)\n",
        "  'xgbclassifier__colsample_bytree':  [0.8, 1.0],             # Fraction of features used for training each tree (column subsampling ratio)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6YFhazFMPdd"
      },
      "outputs": [],
      "source": [
        "enhanced_param_grid = {\n",
        "  'truncatedsvd__n_components': [150, 175, 200, 225, 250],          # Enhanced range for the number of components in Truncated SVD\n",
        "  'xgbclassifier__n_estimators': [30, 50, 70],                      # Enhanced range for the number of boosting rounds in XGBoost\n",
        "  'xgbclassifier__max_depth': [2, 3, 4],                            # Enhanced range for the maximum depth of each tree in XGBoost\n",
        "  'xgbclassifier__learning_rate': [0.005, 0.01, 0.05, 0.1, 0.15],   # Enhanced range for the learning rate in XGBoost\n",
        "  'xgbclassifier__subsample': [0.5, 0.6, 0.8],                      # Enhanced range for the subsample ratio in XGBoost\n",
        "  'xgbclassifier__colsample_bytree':  [0.5, 0.6, 0.8],              # Enhanced range for the column subsampling ratio in XGBoost\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH9ckPz9pD8f"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV1E1he5pHAE",
        "outputId": "a2f5ea5b-e5d3-416c-a28e-ac0d1d64dad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 1.0, 'xgbclassifier__n_estimators': 150, 'xgbclassifier__max_depth': 5, 'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 200}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.550825\n",
            "1  Precision  0.562771\n",
            "2     Recall  0.551315\n",
            "3   F1-Score  0.556984\n",
            "4        AUC  0.550813\n",
            "5   Log-Loss  0.690280\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 618                 505\n",
            "Actual Negative                 529                 650\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid,metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TdizZApp6cd"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DTIzS8OqH7N",
        "outputId": "197f20ee-0941-4566-ff81-5e78549223aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 150, 'xgbclassifier__max_depth': 7, 'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__colsample_bytree': 1.0, 'truncatedsvd__n_components': 200}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.556907\n",
            "1  Precision  0.564792\n",
            "2     Recall  0.587786\n",
            "3   F1-Score  0.576060\n",
            "4        AUC  0.556137\n",
            "5   Log-Loss  0.702545\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 589                 534\n",
            "Actual Negative                 486                 693\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test,metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid,metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhBhjmG9Q-PA"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtTDMLYNaL9Z",
        "outputId": "a8ba7157-198c-407f-fbbe-9bdddc6af827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 100, 'xgbclassifier__max_depth': 7, 'xgbclassifier__learning_rate': 0.2, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 250}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.543875\n",
            "1  Precision  0.542574\n",
            "2     Recall  0.697201\n",
            "3   F1-Score  0.610245\n",
            "4        AUC  0.540052\n",
            "5   Log-Loss  0.769277\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 430                 693\n",
            "Actual Negative                 357                 822\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid,metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYVeJ-fLUGYk"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIPSMHCZUF3S",
        "outputId": "f41826a0-2717-4f8a-ad1e-bc11918c6e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 50, 'xgbclassifier__max_depth': 3, 'xgbclassifier__learning_rate': 0.01, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 200}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.517376\n",
            "1  Precision  0.517400\n",
            "2     Recall  0.857506\n",
            "3   F1-Score  0.645388\n",
            "4        AUC  0.508896\n",
            "5   Log-Loss  0.692628\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 180                 943\n",
            "Actual Negative                 168                1011\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid,metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "322iMKuvi26V"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "idMBuw6KLJPa"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'logisticregression__solver': ['saga'],\n",
        "    'logisticregression__penalty': ['l1', 'l2'],\n",
        "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Adjust the range based on the characteristics of your data\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FLV_drUIqJ4"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHFIZlGSIp1d",
        "outputId": "7ef00ef2-8473-4df9-8f76-25748d75d13f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l1', 'logisticregression__C': 0.1}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.525630\n",
            "1  Precision  0.521610\n",
            "2     Recall  0.890585\n",
            "3   F1-Score  0.657895\n",
            "4        AUC  0.516530\n",
            "5   Log-Loss  0.692039\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 160                 963\n",
            "Actual Negative                 129                1050\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TRehJnsIqND"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky6HH6pyIpxN",
        "outputId": "3625fb42-e133-4451-e8f6-30b4b854e6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l1', 'logisticregression__C': 100}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.513901\n",
            "1  Precision  0.513453\n",
            "2     Recall  0.971162\n",
            "3   F1-Score  0.671751\n",
            "4        AUC  0.502500\n",
            "5   Log-Loss  0.691856\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                  38                1085\n",
            "Actual Negative                  34                1145\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-M2YnogoaaF"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh7MahEdIl3f",
        "outputId": "885c4128-7e82-4734-8c53-ee1c774d6b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l2', 'logisticregression__C': 10}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.525630\n",
            "1  Precision  0.521271\n",
            "2     Recall  0.904156\n",
            "3   F1-Score  0.661290\n",
            "4        AUC  0.516192\n",
            "5   Log-Loss  0.692548\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 144                 979\n",
            "Actual Negative                 113                1066\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zen4PB78Hwon"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DogxZmvd-bnP",
        "outputId": "a8406c5d-bbe0-432f-c936-b8c4fcf69312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l1', 'logisticregression__C': 100}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.507819\n",
            "1  Precision  0.510177\n",
            "2     Recall  0.977947\n",
            "3   F1-Score  0.670544\n",
            "4        AUC  0.496097\n",
            "5   Log-Loss  0.693505\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                  16                1107\n",
            "Actual Negative                  26                1153\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine"
      ],
      "metadata": {
        "id": "whj969mudljU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10],              # Regularization parameter\n",
        "    'svc__kernel': ['linear', 'rbf'],    # Kernel type\n",
        "    'svc__gamma': ['scale', 'auto'],     # Kernel coefficient\n",
        "}"
      ],
      "metadata": {
        "id": "64RR0xu9dXXs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ],
      "metadata": {
        "id": "lIoOQC9U3ifv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "model = 'svm'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "svm_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ],
      "metadata": {
        "id": "MrfJfLNO3rKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ],
      "metadata": {
        "id": "3xl1PySC3idA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "model = 'svm'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "svm_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ],
      "metadata": {
        "id": "AlhA462l3tuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ],
      "metadata": {
        "id": "aCQW7g923iaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "model = 'svm'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "svm_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ],
      "metadata": {
        "id": "YMLxP-mJ3vtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machine Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ],
      "metadata": {
        "id": "b3Skf5AmdqmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "model = 'svm'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "svm_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rMuaGmfdtPq",
        "outputId": "99e8cde9-56f0-4949-c73a-c0324dbf3883"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'svc__kernel': 'rbf', 'svc__gamma': 'scale', 'svc__C': 10}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.516073\n",
            "1  Precision  0.514646\n",
            "2     Recall  0.968617\n",
            "3   F1-Score  0.672160\n",
            "4        AUC  0.504790\n",
            "5   Log-Loss  0.692571\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                  46                1077\n",
            "Actual Negative                  37                1142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbors"
      ],
      "metadata": {
        "id": "nihU1Me_eeO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'kneighborsclassifier__n_neighbors': [3, 5, 7],            # Number of neighbors\n",
        "    'kneighborsclassifier__weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
        "    'kneighborsclassifier__p': [1, 2],                         # Power parameter for Minkowski metric\n",
        "}"
      ],
      "metadata": {
        "id": "-4EIq9sbeiDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ],
      "metadata": {
        "id": "2_I3xr8R4L_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "model = 'knn'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "knn_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ],
      "metadata": {
        "id": "_edlvIot4U-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ],
      "metadata": {
        "id": "Olv2kPH64L6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "model = 'knn'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "knn_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ],
      "metadata": {
        "id": "JR2sMbiy4Up3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ],
      "metadata": {
        "id": "m9nFLdyr4L0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "model = 'knn'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "knn_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ],
      "metadata": {
        "id": "UAcWIK9q4UMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ],
      "metadata": {
        "id": "WPiFUZllfQaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "model = 'knn'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "knn_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ],
      "metadata": {
        "id": "x_4uzFrwfUkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Ranking Comparison"
      ],
      "metadata": {
        "id": "8bBQ798Ix0Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Names (Need string values for dataframe column)\n",
        "model_list = [xgb_count_1, xgb_tfidf_1, xgb_count_2, log_count_1, log_count_2, log_tfidf_1, log_tfidf_2, svm_count_1, svm_count_2, svm_tfidf_1, svm_tfidf_2, knn_count_1, knn_count_2, knn_tfidf_1, knn_tfidf_2]\n",
        "model_str = ['xgb_count_1', 'xgb_tfidf_1', 'xgb_count_2', 'log_count_1', 'log_count_2', 'log_tfidf_1', 'log_tfidf_2', 'svm_count_1', 'svm_count_2', 'svm_tfidf_1', 'svm_tfidf_2', 'knn_count_1', 'knn_count_2', 'knn_tfidf_1', 'knn_tfidf_2']\n",
        "\n",
        "# Specify the metric to rank the models by\n",
        "model_rank_result = model_rank(model_list, model_str, 'AUC')\n",
        "model_rank_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pwqEjyuFklr9",
        "outputId": "42cea569-4499-40a9-dd6f-ee0088da2254"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    model_name    Metric     Score\n",
              "0  log_count_2  F1-Score  0.671751\n",
              "1  log_count_1  F1-Score  0.657895\n",
              "2  xgb_count_2  F1-Score  0.610245\n",
              "3  xgb_tfidf_1  F1-Score  0.576060\n",
              "4  xgb_count_1  F1-Score  0.556984"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2acaa1c1-0e06-4c76-a7bc-1020b8a590d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>Metric</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_count_2</td>\n",
              "      <td>F1-Score</td>\n",
              "      <td>0.671751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_count_1</td>\n",
              "      <td>F1-Score</td>\n",
              "      <td>0.657895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xgb_count_2</td>\n",
              "      <td>F1-Score</td>\n",
              "      <td>0.610245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xgb_tfidf_1</td>\n",
              "      <td>F1-Score</td>\n",
              "      <td>0.576060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xgb_count_1</td>\n",
              "      <td>F1-Score</td>\n",
              "      <td>0.556984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2acaa1c1-0e06-4c76-a7bc-1020b8a590d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2acaa1c1-0e06-4c76-a7bc-1020b8a590d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2acaa1c1-0e06-4c76-a7bc-1020b8a590d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33cd3899-09de-4724-912e-35aaec306da3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33cd3899-09de-4724-912e-35aaec306da3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33cd3899-09de-4724-912e-35aaec306da3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpXbxovwpwhV"
      },
      "source": [
        "# Evaluate model on test set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeuLUrWJOEed"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "y_test_pred = xgb_svd_model.predict(X_test_vcount_bi)\n",
        "metrics_test_df, confusion_test_df = model_eval(xgb_svd_model, X_test_vcount_bi, y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcVKm1Lf8UMY"
      },
      "source": [
        "# Write best model and data to shared drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decommissioned code"
      ],
      "metadata": {
        "id": "EXaGDNXl2em0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdKBq7ETihSJ"
      },
      "source": [
        "## Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JN7diHaUK4sh"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'truncatedsvd__n_components': [150, 200, 250],                                                        # Number of components to keep after dimensionality reduction using Truncated SVD\n",
        "    'randomforestclassifier__n_estimators': [int(x) for x in np.linspace(start=200, stop=2000, num=10)],  # Number of trees in the forest\n",
        "    'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2'],                                     # Number of features to consider at every split\n",
        "    'randomforestclassifier__max_depth': [int(x) for x in np.linspace(10, 110, num=11)],                  # Maximum depth of the tree\n",
        "    'randomforestclassifier__min_samples_split': [2, 5, 10],                                              # Minimum number of samples required to split an internal node\n",
        "    'randomforestclassifier__min_samples_leaf': [1, 2, 4],                                                # Minimum number of samples required to be at a leaf node\n",
        "    'randomforestclassifier__bootstrap': [True, False]                                                    # Method of selecting samples for training each tree\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-IjvxnzJRIs"
      },
      "source": [
        "### Random Forest Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgo5suaYJQtN",
        "outputId": "4084ddad-07e7-422f-bd97-f5280337d0dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'truncatedsvd__n_components': 200, 'randomforestclassifier__n_estimators': 1800, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__max_depth': 80, 'randomforestclassifier__bootstrap': True}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.567333\n",
            "1  Precision  0.566161\n",
            "2     Recall  0.664122\n",
            "3   F1-Score  0.611241\n",
            "4        AUC  0.564919\n",
            "5   Log-Loss  0.666130\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 523                 600\n",
            "Actual Negative                 396                 783\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'rf'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'f1'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "rf_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU5wDIxbJQ8C"
      },
      "source": [
        "### Random Forest Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SsLCJbmJJQou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f5911a-1f7b-48eb-a585-12e0e9fcf2e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'truncatedsvd__n_components': 200, 'randomforestclassifier__n_estimators': 1800, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__max_depth': 80, 'randomforestclassifier__bootstrap': True}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.544309\n",
            "1  Precision  0.540323\n",
            "2     Recall  0.738762\n",
            "3   F1-Score  0.624149\n",
            "4        AUC  0.539461\n",
            "5   Log-Loss  0.688715\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 382                 741\n",
            "Actual Negative                 308                 871\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'rf'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'f1'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "rf_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8gaKVETJQ0Q"
      },
      "source": [
        "### Random Forest Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4pkI77HJQeE"
      },
      "outputs": [],
      "source": [
        "# Define variables\n",
        "model = 'rf'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'f1'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "rf_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FtabLhhJQ2x"
      },
      "source": [
        "### Random Forest Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2ncMEpAJQbg"
      },
      "outputs": [],
      "source": [
        "# Define variables\n",
        "model = 'rf'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'f1'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "rf_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "attu5aSwi0cS"
      },
      "outputs": [],
      "source": [
        "# Save the vectorizer and associated data\n",
        "joblib.dump(vectorizer_tfidf_bi,folder_path+'tfidf_vectorizer_bi.pkl')\n",
        "joblib.dump(X_train_vtfidf_bi, folder_path+'X_train_vtfidf_bi.pkl')\n",
        "joblib.dump(X_validation_vtfidf_bi, folder_path+'X_validation_vtfidf_bi.pkl')\n",
        "joblib.dump(X_test_vtfidf_bi, folder_path+'X_test_vtfidf_bi.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sdKBq7ETihSJ"
      ],
      "authorship_tag": "ABX9TyP3c38RwDJp/af9CyRRJ8ub",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}