{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-atallah/implicit_gender_bias/blob/main/Supervised_Learning_Dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io7VcWs4weYO"
      },
      "source": [
        "Next Steps:\n",
        "\n",
        "*  Test not removing stop words - Done, saw improvement\n",
        "*  Fix Log regression issue\n",
        "  * May be a class imbalance - Checked into this and found no imbalance. I tried scoring on AUC-PR and the model results were better but still not great. I believe a logistic regression may be to simple of a model to work with our data.\n",
        "* Score random search on AUC-PR\n",
        "  * Log regression performance was enhanced by AUC-PR score. I am now testing the best xgb model using AUC-PR. On great lakes I am running the last two random forest models.\n",
        "* Use grid search rather than random search in great lakes cluster.\n",
        "\n",
        "* Once I get the auc-pr tested XGB I will save results and try removing the stop word removal and rescore the XGB model. Once I have the best of those results I will work on using grid search with a narrowed down search range. I will do that step in great lakes for efficiency.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHf_jOR9jOca"
      },
      "source": [
        "# Import, Download, & Variable Statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6WzZ3_ujTwL",
        "outputId": "5155469d-6a35-4835-d3bf-b982720909af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'implicit_gender_bias' already exists and is not an empty directory.\r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/gibsonce/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/gibsonce/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/gibsonce/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import & download statements\n",
        "# General Statements\n",
        "!git clone https://github.com/d-atallah/implicit_gender_bias.git\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import joblib\n",
        "from implicit_gender_bias import config as cf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Feature selection & Model tuning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.decomposition import TruncatedSVD,PCA, NMF\n",
        "from sklearn.metrics import confusion_matrix,precision_score, recall_score, f1_score, accuracy_score, roc_curve, roc_auc_score, log_loss, make_scorer, average_precision_score\n",
        "\n",
        "# Model options\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# NLTK resources\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPZ-eni9oS-A",
        "outputId": "7601f13f-a6c7-4ce5-e631-48888d597a14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (1,4,6,7,10,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "# Variables\n",
        "# Inputs\n",
        "folder_path = '/home/gibsonce/datallah-jaymefis-gibsonce/'#cf.filepath() #'/home/gibsonce/datallah-jaymefis-gibsonce/'\n",
        "csv_files = ['facebook_wiki_posts','facebook_wiki_responses','fitocracy_posts','fitocracy_responses','reddit_posts','reddit_responses','ted_responses','facebook_congress_posts','annotations','facebook_congress_responses']\n",
        "\n",
        "annotations = pd.read_csv(folder_path+'annotations_combined.csv')\n",
        "responses_combined = pd.read_csv(folder_path+'responses_combined.csv')\n",
        "#posts_combined = pd.read_csv(folder_path+'posts_combined.csv')\n",
        "#sources_combined = pd.read_csv(folder_path+'sources_combined_output.csv')\n",
        "\n",
        "# Outputs\n",
        "test_num = '2'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zRF7xFVjBKo"
      },
      "source": [
        "## Define Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zLj7yI_jJcQ"
      },
      "outputs": [],
      "source": [
        "# Evaluate a model\n",
        "def model_eval(model, X_test, y_test, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluates a specified model using accuracy, precision, recall, F-1 score, AUC, log-Loss, and a confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained model to be evaluated.\n",
        "    - X_test (list or array): Test set features.\n",
        "    - y_test (list or array): True labels.\n",
        "    - y_pred (list or array): Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "    - metrics_df (pd.DataFrame): DataFrame containing the metrics and scores.\n",
        "    - confusion_df (pd.DataFrame): DataFrame containing a confusion matrix.\n",
        "    \"\"\"\n",
        "    # Initialize dataframes\n",
        "    metrics_df = pd.DataFrame(columns=['Metric', 'Score'])\n",
        "    confusion_df = pd.DataFrame(columns=['Actual Positive', 'Actual Negative', 'Predicted Positive', 'Predicted Negative'])\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "                                                      'Score': [accuracy, precision, recall, f1]})])\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['AUC'],\n",
        "                                                      'Score': [auc]})])\n",
        "\n",
        "    logloss = log_loss(y_test, model.predict_proba(X_test))\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['Log-Loss'],\n",
        "                                                      'Score': [logloss]})])\n",
        "\n",
        "    # Reset index\n",
        "    metrics_df = metrics_df.reset_index(drop=True)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    confusion_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "\n",
        "    # Print dataframes\n",
        "    print(\"Metrics:\")\n",
        "    print(metrics_df)\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_df)\n",
        "\n",
        "    return metrics_df, confusion_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pscLi2HiU1CL"
      },
      "outputs": [],
      "source": [
        "stop_words = {'a',\n",
        " 'about',\n",
        " 'above',\n",
        " 'after',\n",
        " 'again',\n",
        " 'against',\n",
        " 'ain',\n",
        " 'all',\n",
        " 'am',\n",
        " 'an',\n",
        " 'and',\n",
        " 'any',\n",
        " 'are',\n",
        " 'aren',\n",
        " \"aren't\",\n",
        " 'as',\n",
        " 'at',\n",
        " 'be',\n",
        " 'because',\n",
        " 'been',\n",
        " 'before',\n",
        " 'being',\n",
        " 'below',\n",
        " 'between',\n",
        " 'both',\n",
        " 'but',\n",
        " 'by',\n",
        " 'can',\n",
        " 'couldn',\n",
        " \"couldn't\",\n",
        " 'd',\n",
        " 'did',\n",
        " 'didn',\n",
        " \"didn't\",\n",
        " 'do',\n",
        " 'does',\n",
        " 'doesn',\n",
        " \"doesn't\",\n",
        " 'doing',\n",
        " 'don',\n",
        " \"don't\",\n",
        " 'down',\n",
        " 'during',\n",
        " 'each',\n",
        " 'few',\n",
        " 'for',\n",
        " 'from',\n",
        " 'further',\n",
        " 'had',\n",
        " 'hadn',\n",
        " \"hadn't\",\n",
        " 'has',\n",
        " 'hasn',\n",
        " \"hasn't\",\n",
        " 'have',\n",
        " 'haven',\n",
        " \"haven't\",\n",
        " 'having',\n",
        " #'he',\n",
        " #'her',\n",
        " 'here',\n",
        " #'hers',\n",
        " #'herself',\n",
        " #'him',\n",
        " #'himself',\n",
        " #'his',\n",
        " 'how',\n",
        " 'i',\n",
        " 'if',\n",
        " 'in',\n",
        " 'into',\n",
        " 'is',\n",
        " 'isn',\n",
        " \"isn't\",\n",
        " 'it',\n",
        " \"it's\",\n",
        " 'its',\n",
        " 'itself',\n",
        " 'just',\n",
        " 'll',\n",
        " 'm',\n",
        " 'ma',\n",
        " 'me',\n",
        " 'mightn',\n",
        " \"mightn't\",\n",
        " 'more',\n",
        " 'most',\n",
        " 'mustn',\n",
        " \"mustn't\",\n",
        " 'my',\n",
        " 'myself',\n",
        " 'needn',\n",
        " \"needn't\",\n",
        " 'no',\n",
        " 'nor',\n",
        " 'not',\n",
        " 'now',\n",
        " 'o',\n",
        " 'of',\n",
        " 'off',\n",
        " 'on',\n",
        " 'once',\n",
        " 'only',\n",
        " 'or',\n",
        " 'other',\n",
        " 'our',\n",
        " 'ours',\n",
        " 'ourselves',\n",
        " 'out',\n",
        " 'over',\n",
        " 'own',\n",
        " 're',\n",
        " 's',\n",
        " 'same',\n",
        " 'shan',\n",
        " \"shan't\",\n",
        " #'she',\n",
        " #\"she's\",\n",
        " 'should',\n",
        " \"should've\",\n",
        " 'shouldn',\n",
        " \"shouldn't\",\n",
        " 'so',\n",
        " 'some',\n",
        " 'such',\n",
        " 't',\n",
        " 'than',\n",
        " 'that',\n",
        " \"that'll\",\n",
        " 'the',\n",
        " 'their',\n",
        " 'theirs',\n",
        " 'them',\n",
        " 'themselves',\n",
        " 'then',\n",
        " 'there',\n",
        " 'these',\n",
        " 'they',\n",
        " 'this',\n",
        " 'those',\n",
        " 'through',\n",
        " 'to',\n",
        " 'too',\n",
        " 'under',\n",
        " 'until',\n",
        " 'up',\n",
        " 've',\n",
        " 'very',\n",
        " 'was',\n",
        " 'wasn',\n",
        " \"wasn't\",\n",
        " 'we',\n",
        " 'were',\n",
        " 'weren',\n",
        " \"weren't\",\n",
        " 'what',\n",
        " 'when',\n",
        " 'where',\n",
        " 'which',\n",
        " 'while',\n",
        " 'who',\n",
        " 'whom',\n",
        " 'why',\n",
        " 'will',\n",
        " 'with',\n",
        " 'won',\n",
        " \"won't\",\n",
        " 'wouldn',\n",
        " \"wouldn't\",\n",
        " 'y',\n",
        " 'you',\n",
        " \"you'd\",\n",
        " \"you'll\",\n",
        " \"you're\",\n",
        " \"you've\",\n",
        " 'your',\n",
        " 'yours',\n",
        " 'yourself',\n",
        " 'yourselves'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1jh0q60RcvF"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Applies text preprocessing to a given text, including:\n",
        "    - Removing special characters and digits\n",
        "    - Converting to lowercase\n",
        "    - Tokenization and removing stopwords\n",
        "    - Lemmatization and stemming\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): Input text to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "    - processed_text (str): Preprocessed text after applying the specified steps.\n",
        "    \"\"\"\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenization and removing stopwords\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization and stemming\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    tokens = [porter.stem(word) for word in tokens]\n",
        "\n",
        "    # Rejoin tokens into a processed text\n",
        "    processed_text = ' '.join(tokens)\n",
        "\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leBXV_yJb04G"
      },
      "outputs": [],
      "source": [
        "def model_search(X_train, y_train, X_validation, y_validation, X_test, model_type, vectorizer, ngram, search_type, param_grid, metric_score):\n",
        "  \"\"\"\n",
        "  Searches for the best hyperparameters for a specified model and dimensionality reduction method using GridSearchCV or RandomizedSearchCV.\n",
        "\n",
        "  Parameters:\n",
        "  - X_train (array-like): Training set features, preprocessed.\n",
        "  - y_train (array-like): Training set labels.\n",
        "  - X_validation (array-like): Validation set features, preprocessed.\n",
        "  - y_validation (array-like): Validation set labels.\n",
        "  - X_test (array-like): Test set features, preprocessed.\n",
        "  - model_type (str): Type of model to test. Choose from 'log' (Logistic Regression), 'xgb' (XGBoost), or 'rf' (Random Forest), 'knn' (k-Nearest Neighbors), 'svm' (Support Vector Machine).\n",
        "  - vectorizer (str): Type of vectorizer to test. Choose from 'count' (Count Vecotizer) or 'tfidf' (TF-IDF Vecotizer).\n",
        "  - ngram (int): Feature representation to test. Choose 1 for unigrams, 2 for bigrams, and so on.\n",
        "  - search_type (str): Defines grid search or random search style. Choose from 'grid' (Grid Search), 'rand' (Random Search).\n",
        "  - param_grid (dict): Hyperparameter grid for the specified model and dimensionality reduction method.\n",
        "  - metric_score (str): Defines metric to score search on. Choose from 'f1' (F-1), 'auc-pr' (area under the precision-recall curve). *We can add more options if needed.\n",
        "\n",
        "  Returns:\n",
        "  - selected_model: Trained model with the best hyperparameters.\n",
        "  - selected_params (dict): Best hyperparameters found during the search.\n",
        "  - X_train_ (array-like): Vectorized training set features.\n",
        "  - X_validation_ (array-like): Vectorized validation set features.\n",
        "  - X_test_ (array-like): Vectorized test set features.\n",
        "  \"\"\"\n",
        "  if vectorizer == 'count':\n",
        "    vect = CountVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "  elif vectorizer == 'tfidf':\n",
        "    vect = TfidfVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "  else:\n",
        "      raise ValueError(\"Invalid vector type. Use 'count' or 'tfidf'.\")\n",
        "\n",
        "  if model_type == 'log':\n",
        "      model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "  elif model_type == 'xgb':\n",
        "      model = XGBClassifier(random_state=42)\n",
        "  elif model_type == 'rf':\n",
        "      model = RandomForestClassifier(random_state=42)\n",
        "  elif model_type == 'knn':\n",
        "      model = KNeighborsClassifier()\n",
        "  elif model_type == 'svm':\n",
        "      model =  SVC(probability=True)\n",
        "  else:\n",
        "      raise ValueError(\"Invalid model type. Use 'xgb', 'rf', 'svm', 'knn', or 'log'.\")\n",
        "\n",
        "  # Pipeline with dimensionality reduction method and model to test\n",
        "  #Chose SVD ad reduction method because the data is sparse (PCA and NMF not applicable)\n",
        "  pipeline = make_pipeline(\n",
        "    TruncatedSVD(random_state=42),\n",
        "    model\n",
        "  )\n",
        "\n",
        "  # Cross-validation StratifiedKFold for classification (Reduce risk of overfitting)\n",
        "  cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "  if metric_score == 'f1':\n",
        "    scorer = make_scorer(f1_score)\n",
        "  elif metric_score == 'auc-pr':\n",
        "    scorer = make_scorer(average_precision_score)\n",
        "\n",
        "  if search_type == 'grid':\n",
        "    # Use F1-score as the scoring metric in GridSearchCV (This can be changed to any other metric)\n",
        "\n",
        "    search = GridSearchCV(\n",
        "        pipeline, param_grid, cv=cv, scoring=scorer, n_jobs=-1\n",
        "    )\n",
        "    # Fit the grid search to the data\n",
        "    search.fit(X_train_, y_train)\n",
        "\n",
        "  elif search_type == 'random':\n",
        "\n",
        "    # Use F1-score as the scoring metric in RandomizedSearchCV\n",
        "    search = RandomizedSearchCV(\n",
        "      pipeline, param_grid, cv=cv, scoring=scorer, n_iter=10, n_jobs=-1, random_state=42\n",
        "    )\n",
        "    # Fit random search to the data\n",
        "    search.fit(X_train_, y_train)\n",
        "\n",
        "  else:\n",
        "    raise ValueError(\"Invalid search type. Use 'grid' or 'random'.\")\n",
        "\n",
        "  # Get best parameters\n",
        "  selected_params = search.best_params_\n",
        "  print(f\"Hyperparameters:\", selected_params)\n",
        "\n",
        "  # Train a new model with the best hyperparameters\n",
        "  selected_model = search.best_estimator_\n",
        "\n",
        "  # Evaluate the model on the validation set\n",
        "  y_val_pred = selected_model.predict(X_validation_)\n",
        "  metrics_val_df, confusion_val_df = model_eval(selected_model, X_validation_, y_validation, y_val_pred)\n",
        "\n",
        "  return selected_model, selected_params, X_train_, X_validation_, X_test_, metrics_val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ9IeKzIkjZx"
      },
      "outputs": [],
      "source": [
        "def model_rank(model_list, model_str, metric):\n",
        "    \"\"\"\n",
        "    Finds the model with the best score based on a specified metric.\n",
        "\n",
        "    Parameters:\n",
        "    - models_list (list): List of dictionaries, each representing a model's details.\n",
        "    - model_str (list): List of model names corresponding to models_list.\n",
        "    - metric (str): Metric to rank the models by (e.g., 'Accuracy', 'F1-Score').\n",
        "\n",
        "    Returns:\n",
        "    - all_models (pd.DataFrame): DataFrame with metric scores and model names.\n",
        "    - models_by_metric (pd.DataFrame): DataFrame filtered by the specified metric and sorted in descending order.\n",
        "    \"\"\"\n",
        "    all_models = [model_dict['metrics'].assign(Model=model_name) for model_dict, model_name in zip(model_list, model_str)]\n",
        "\n",
        "    # Concatenate the DataFrames in the list\n",
        "    all_models = pd.concat(all_models, ignore_index=True)\n",
        "\n",
        "\n",
        "    # Sort the DataFrame by the specified metric in descending order\n",
        "    models_by_metric = all_models[all_models['Metric'] == metric].sort_values(by='Score', ascending=False)\n",
        "\n",
        "    return all_models, models_by_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OZmlCPsrWD6"
      },
      "source": [
        "# Train, Validate, Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlNBS5XIrOBP"
      },
      "outputs": [],
      "source": [
        "# Annotation only\n",
        "# Set train-test split variables\n",
        "X = annotations['response_text']\n",
        "y = annotations['op_gender_binary']\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Split the temp set into validation and test sets\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRKA5ev5QbwY"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to each set (X_train, X_validation, X_test)\n",
        "X_train_preprocessed = X_train.apply(preprocess_text)\n",
        "X_validation_preprocessed = X_validation.apply(preprocess_text)\n",
        "X_test_preprocessed = X_test.apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TLh5IitPSwQ"
      },
      "source": [
        "Check for class imbalance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOundgQTOvwp",
        "outputId": "6431852b-7612-46b3-f7bd-8415424034f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    5464\n",
              "0    5281\n",
              "Name: op_gender_binary, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_distribution = pd.Series(y_train).value_counts()\n",
        "class_distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsUhDyhs-EK"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdIbADLEKghY"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "  'truncatedsvd__n_components': [150, 200, 250],              # Number of components to keep after dimensionality reduction using Truncated SVD\n",
        "  'xgbclassifier__n_estimators': [50, 100, 150],              # Number of boosting rounds (trees) in the XGBoost model\n",
        "  'xgbclassifier__max_depth': [3, 5, 7],                      # Maximum depth of each tree in the XGBoost model\n",
        "  'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],           # Step size shrinkage used in boosting (controls the learning rate)\n",
        "  'xgbclassifier__subsample': [0.8, 1.0],                     # Fraction of samples used for training each tree (subsample ratio)\n",
        "  'xgbclassifier__colsample_bytree':  [0.8, 1.0],             # Fraction of features used for training each tree (column subsampling ratio)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6YFhazFMPdd"
      },
      "outputs": [],
      "source": [
        "#Enhanced after random search\n",
        "param_grid = {\n",
        "  'truncatedsvd__n_components': [125, 150, 175],          # Enhanced range for the number of components in Truncated SVD\n",
        "  'xgbclassifier__n_estimators': [130, 150, 170],                      # Enhanced range for the number of boosting rounds in XGBoost\n",
        "  'xgbclassifier__max_depth': [7, 8, 9],                            # Enhanced range for the maximum depth of each tree in XGBoost\n",
        "  'xgbclassifier__learning_rate': [0.05, 0.1, 0.15],   # Enhanced range for the learning rate in XGBoost\n",
        "  'xgbclassifier__subsample': [0.5, 0.6, 0.8],                      # Enhanced range for the subsample ratio in XGBoost\n",
        "  'xgbclassifier__colsample_bytree':  [.5, .8, 1.0],              # Enhanced range for the column subsampling ratio in XGBoost\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH9ckPz9pD8f"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV1E1he5pHAE",
        "outputId": "a2f5ea5b-e5d3-416c-a28e-ac0d1d64dad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 1.0, 'xgbclassifier__n_estimators': 150, 'xgbclassifier__max_depth': 5, 'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 200}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.550825\n",
            "1  Precision  0.562771\n",
            "2     Recall  0.551315\n",
            "3   F1-Score  0.556984\n",
            "4        AUC  0.550813\n",
            "5   Log-Loss  0.690280\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 618                 505\n",
            "Actual Negative                 529                 650\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid,metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhBhjmG9Q-PA"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtTDMLYNaL9Z",
        "outputId": "a8ba7157-198c-407f-fbbe-9bdddc6af827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 150, 'xgbclassifier__max_depth': 9, 'xgbclassifier__learning_rate': 0.05, 'xgbclassifier__colsample_bytree': 0.5, 'truncatedsvd__n_components': 150}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.552997\n",
            "1  Precision  0.549020\n",
            "2     Recall  0.712468\n",
            "3   F1-Score  0.620155\n",
            "4        AUC  0.549021\n",
            "5   Log-Loss  0.709090\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 433                 690\n",
            "Actual Negative                 339                 840\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid,metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TdizZApp6cd"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DTIzS8OqH7N",
        "outputId": "197f20ee-0941-4566-ff81-5e78549223aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 150, 'xgbclassifier__max_depth': 9, 'xgbclassifier__learning_rate': 0.02, 'xgbclassifier__colsample_bytree': 0.4, 'truncatedsvd__n_components': 150}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.552129\n",
            "1  Precision  0.558730\n",
            "2     Recall  0.597116\n",
            "3   F1-Score  0.577286\n",
            "4        AUC  0.551007\n",
            "5   Log-Loss  0.675757\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 567                 556\n",
            "Actual Negative                 475                 704\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test,metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid,metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL1uDk_-5y-b"
      },
      "source": [
        "### XGB Final Model:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cBARyxv5y-b",
        "outputId": "ea051212-e4b6-4771-fc2d-674d1585c416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.577073\n",
            "1  Precision  0.572856\n",
            "2     Recall  0.598782\n",
            "3   F1-Score  0.585532\n",
            "4        AUC  0.577120\n",
            "5   Log-Loss  0.670886\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 641                 513\n",
            "Actual Negative                 461                 688\n"
          ]
        }
      ],
      "source": [
        "vect = TfidfVectorizer(ngram_range=(ngram, ngram))\n",
        "    X_train_ = vect.fit_transform(X_train)\n",
        "    X_validation_ = vect.transform(X_validation)\n",
        "    X_test_ = vect.transform(X_test)\n",
        "\n",
        "test = X_test_final\n",
        "train = X_train_final\n",
        "best_hyperparameters = {'xgbclassifier__subsample': 0.8, 'xgbclassifier__n_estimators': 150, 'xgbclassifier__max_depth': 9, 'xgbclassifier__learning_rate': 0.05, 'xgbclassifier__colsample_bytree': 0.5, 'truncatedsvd__n_components': 150}\n",
        "\n",
        "# Create the final pipeline\n",
        "final_model_pipeline = make_pipeline(\n",
        "    TruncatedSVD(n_components=best_hyperparameters['truncatedsvd__n_components'], random_state=42),\n",
        "    XGBClassifier(\n",
        "        subsample=best_hyperparameters['xgbclassifier__subsample'],\n",
        "        n_estimators=best_hyperparameters['xgbclassifier__n_estimators'],\n",
        "        max_depth=best_hyperparameters['xgbclassifier__max_depth'],\n",
        "        learning_rate=best_hyperparameters['xgbclassifier__learning_rate'],\n",
        "        colsample_bytree=best_hyperparameters['xgbclassifier__colsample_bytree'],\n",
        "        random_state=42\n",
        "    )\n",
        ")\n",
        "\n",
        "# Fit the final model\n",
        "final_model_pipeline.fit(X_train_final, y_train)\n",
        "\n",
        "# Evaluate the final model on the test set\n",
        "y_test_pred = final_model_pipeline.predict(X_test_final)\n",
        "metrics_test_df, confusion_test_df = model_eval(final_model_pipeline, X_test_final, y_test, y_test_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYVeJ-fLUGYk"
      },
      "source": [
        "### XGB Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIPSMHCZUF3S",
        "outputId": "f41826a0-2717-4f8a-ad1e-bc11918c6e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'xgbclassifier__subsample': 0.6, 'xgbclassifier__n_estimators': 150, 'xgbclassifier__max_depth': 7, 'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__colsample_bytree': 0.8, 'truncatedsvd__n_components': 150}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.553432\n",
            "1  Precision  0.549443\n",
            "2     Recall  0.711620\n",
            "3   F1-Score  0.620103\n",
            "4        AUC  0.549488\n",
            "5   Log-Loss  0.726742\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 435                 688\n",
            "Actual Negative                 340                 839\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'xgb'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid,metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "xgb_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "322iMKuvi26V"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idMBuw6KLJPa"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'logisticregression__solver': ['saga'],\n",
        "    'logisticregression__penalty': ['l1', 'l2'],\n",
        "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],  # Adjust the range based on the characteristics of your data\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FLV_drUIqJ4"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHFIZlGSIp1d",
        "outputId": "7ef00ef2-8473-4df9-8f76-25748d75d13f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l1', 'logisticregression__C': 0.1}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.525630\n",
            "1  Precision  0.521610\n",
            "2     Recall  0.890585\n",
            "3   F1-Score  0.657895\n",
            "4        AUC  0.516530\n",
            "5   Log-Loss  0.692039\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 160                 963\n",
            "Actual Negative                 129                1050\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TRehJnsIqND"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky6HH6pyIpxN",
        "outputId": "3625fb42-e133-4451-e8f6-30b4b854e6ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l1', 'logisticregression__C': 100}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.513901\n",
            "1  Precision  0.513453\n",
            "2     Recall  0.971162\n",
            "3   F1-Score  0.671751\n",
            "4        AUC  0.502500\n",
            "5   Log-Loss  0.691856\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                  38                1085\n",
            "Actual Negative                  34                1145\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-M2YnogoaaF"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh7MahEdIl3f",
        "outputId": "885c4128-7e82-4734-8c53-ee1c774d6b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l2', 'logisticregression__C': 100}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.523892\n",
            "1  Precision  0.520039\n",
            "2     Recall  0.913486\n",
            "3   F1-Score  0.662769\n",
            "4        AUC  0.514178\n",
            "5   Log-Loss  0.692581\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 129                 994\n",
            "Actual Negative                 102                1077\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zen4PB78Hwon"
      },
      "source": [
        "### Logistic Regression Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DogxZmvd-bnP",
        "outputId": "a8406c5d-bbe0-432f-c936-b8c4fcf69312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'logisticregression__solver': 'saga', 'logisticregression__penalty': 'l1', 'logisticregression__C': 100}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.507819\n",
            "1  Precision  0.510177\n",
            "2     Recall  0.977947\n",
            "3   F1-Score  0.670544\n",
            "4        AUC  0.496097\n",
            "5   Log-Loss  0.693502\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                  16                1107\n",
            "Actual Negative                  26                1153\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'log'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "log_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whj969mudljU"
      },
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64RR0xu9dXXs"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10],              # Regularization parameter\n",
        "    'svc__kernel': ['linear', 'rbf'],    # Kernel type\n",
        "    'svc__gamma': ['scale', 'auto'],     # Kernel coefficient\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIoOQC9U3ifv"
      },
      "source": [
        "### Support Vector Machine Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrfJfLNO3rKy",
        "outputId": "2060b85a-bdba-4f86-d54c-ff5b6d14df15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'svc__kernel': 'rbf', 'svc__gamma': 'scale', 'svc__C': 10}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.526499\n",
            "1  Precision  0.524930\n",
            "2     Recall  0.794741\n",
            "3   F1-Score  0.632254\n",
            "4        AUC  0.519811\n",
            "5   Log-Loss  0.692200\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 275                 848\n",
            "Actual Negative                 242                 937\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'svm'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "svm_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xl1PySC3idA"
      },
      "source": [
        "### Support Vector Machine Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlhA462l3tuD",
        "outputId": "e4ed2d2f-00db-4592-be08-53a6e38dbc4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'svc__kernel': 'rbf', 'svc__gamma': 'scale', 'svc__C': 10}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.516942\n",
            "1  Precision  0.515276\n",
            "2     Recall  0.958439\n",
            "3   F1-Score  0.670225\n",
            "4        AUC  0.505934\n",
            "5   Log-Loss  0.692596\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                  60                1063\n",
            "Actual Negative                  49                1130\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'svm'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "svm_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCQW7g923iaG"
      },
      "source": [
        "### Support Vector Machine Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMLxP-mJ3vtU",
        "outputId": "0dafe0c7-4d0b-4da1-a4e9-81cfd443399d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'svc__kernel': 'rbf', 'svc__gamma': 'scale', 'svc__C': 10}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.515639\n",
            "1  Precision  0.518223\n",
            "2     Recall  0.771841\n",
            "3   F1-Score  0.620102\n",
            "4        AUC  0.509251\n",
            "5   Log-Loss  0.692726\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 277                 846\n",
            "Actual Negative                 269                 910\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'svm'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "svm_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3Skf5AmdqmS"
      },
      "source": [
        "### Support Vector Machine Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rMuaGmfdtPq",
        "outputId": "99e8cde9-56f0-4949-c73a-c0324dbf3883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'svc__kernel': 'rbf', 'svc__gamma': 'scale', 'svc__C': 10}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.516073\n",
            "1  Precision  0.514646\n",
            "2     Recall  0.968617\n",
            "3   F1-Score  0.672160\n",
            "4        AUC  0.504790\n",
            "5   Log-Loss  0.692515\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                  46                1077\n",
            "Actual Negative                  37                1142\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'svm'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "svm_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nihU1Me_eeO1"
      },
      "source": [
        "## K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4EIq9sbeiDC"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'kneighborsclassifier__n_neighbors': [3, 5, 7],            # Number of neighbors\n",
        "    'kneighborsclassifier__weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
        "    'kneighborsclassifier__p': [1, 2],                         # Power parameter for Minkowski metric\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_I3xr8R4L_x"
      },
      "source": [
        "### K-Nearest Neighbors Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_edlvIot4U-D",
        "outputId": "53656ffd-9e70-442c-821b-08dde22501de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'kneighborsclassifier__weights': 'distance', 'kneighborsclassifier__p': 2, 'kneighborsclassifier__n_neighbors': 7}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.545613\n",
            "1  Precision  0.557180\n",
            "2     Recall  0.549618\n",
            "3   F1-Score  0.553373\n",
            "4        AUC  0.545513\n",
            "5   Log-Loss  1.377242\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 608                 515\n",
            "Actual Negative                 531                 648\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'knn'\n",
        "vectorization = 'count'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "knn_count_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olv2kPH64L6e"
      },
      "source": [
        "### K-Nearest Neighbors Model Method:\n",
        "*   Vectorization: Count\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR2sMbiy4Up3",
        "outputId": "23238eb5-9715-4a20-a369-cf841847956f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'kneighborsclassifier__weights': 'distance', 'kneighborsclassifier__p': 2, 'kneighborsclassifier__n_neighbors': 7}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.544744\n",
            "1  Precision  0.544407\n",
            "2     Recall  0.681086\n",
            "3   F1-Score  0.605124\n",
            "4        AUC  0.541344\n",
            "5   Log-Loss  1.114751\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 451                 672\n",
            "Actual Negative                 376                 803\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'knn'\n",
        "vectorization = 'count'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "knn_count_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9nFLdyr4L0n"
      },
      "source": [
        "### K-Nearest Neighbors Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAcWIK9q4UMu",
        "outputId": "825f1415-2fe3-4434-a858-bd91455e84b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'kneighborsclassifier__weights': 'distance', 'kneighborsclassifier__p': 2, 'kneighborsclassifier__n_neighbors': 7}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.519983\n",
            "1  Precision  0.531040\n",
            "2     Recall  0.536896\n",
            "3   F1-Score  0.533952\n",
            "4        AUC  0.519561\n",
            "5   Log-Loss  1.330992\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 564                 559\n",
            "Actual Negative                 546                 633\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'knn'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 1\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "knn_tfidf_1 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPiFUZllfQaC"
      },
      "source": [
        "### K-Nearest Neighbors Model Method:\n",
        "*   Vectorization: TF-IDF\n",
        "*   Feature Representation: Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_4uzFrwfUkB",
        "outputId": "cf33e98d-bdca-42e3-e9f1-1d74632df237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: {'kneighborsclassifier__weights': 'distance', 'kneighborsclassifier__p': 1, 'kneighborsclassifier__n_neighbors': 3}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.551694\n",
            "1  Precision  0.550034\n",
            "2     Recall  0.685327\n",
            "3   F1-Score  0.610272\n",
            "4        AUC  0.548362\n",
            "5   Log-Loss  7.951702\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 462                 661\n",
            "Actual Negative                 371                 808\n"
          ]
        }
      ],
      "source": [
        "# Define variables\n",
        "model = 'knn'\n",
        "vectorization = 'tfidf'\n",
        "ngram = 2\n",
        "search_type = 'random'\n",
        "metric_score = 'auc-pr'\n",
        "\n",
        "# Run model search\n",
        "model,params,train,validation,test, metrics = model_search(X_train_preprocessed, y_train, X_validation_preprocessed, y_validation, X_test_preprocessed, model, vectorization, ngram, search_type, param_grid, metric_score)\n",
        "\n",
        "# Save results to dictionary\n",
        "knn_tfidf_2 = {\n",
        "    'model': model,\n",
        "    'params': params,\n",
        "    'X_train': train,\n",
        "    'X_validation': validation,\n",
        "    'X_test': test,\n",
        "    'metrics': metrics\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bBQ798Ix0Wl"
      },
      "source": [
        "# Model Ranking Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pwqEjyuFklr9",
        "outputId": "42cea569-4499-40a9-dd6f-ee0088da2254"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Score</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.571551</td>\n",
              "      <td>xgb_tfidf_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.570937</td>\n",
              "      <td>xgb_count_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.570937</td>\n",
              "      <td>xgb_count_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.549021</td>\n",
              "      <td>xgb_count_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.548362</td>\n",
              "      <td>knn_tfidf_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.545513</td>\n",
              "      <td>knn_count_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.541344</td>\n",
              "      <td>knn_count_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.519811</td>\n",
              "      <td>svm_count_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.519561</td>\n",
              "      <td>knn_tfidf_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.516530</td>\n",
              "      <td>log_count_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.514178</td>\n",
              "      <td>log_tfidf_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.509251</td>\n",
              "      <td>svm_tfidf_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.505934</td>\n",
              "      <td>svm_count_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.504790</td>\n",
              "      <td>svm_tfidf_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>log_count_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>AUC</td>\n",
              "      <td>0.496097</td>\n",
              "      <td>log_tfidf_2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Metric     Score        Model\n",
              "10    AUC  0.571551  xgb_tfidf_1\n",
              "4     AUC  0.570937  xgb_count_1\n",
              "16    AUC  0.570937  xgb_count_1\n",
              "22    AUC  0.549021  xgb_count_2\n",
              "94    AUC  0.548362  knn_tfidf_2\n",
              "76    AUC  0.545513  knn_count_1\n",
              "82    AUC  0.541344  knn_count_2\n",
              "52    AUC  0.519811  svm_count_1\n",
              "88    AUC  0.519561  knn_tfidf_1\n",
              "28    AUC  0.516530  log_count_1\n",
              "40    AUC  0.514178  log_tfidf_1\n",
              "64    AUC  0.509251  svm_tfidf_1\n",
              "58    AUC  0.505934  svm_count_2\n",
              "70    AUC  0.504790  svm_tfidf_2\n",
              "34    AUC  0.502500  log_count_2\n",
              "46    AUC  0.496097  log_tfidf_2"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Names (Need string values for dataframe column)\n",
        "model_list = [xgb_count_1, xgb_tfidf_1, xgb_count_1, xgb_count_2, log_count_1, log_count_2, log_tfidf_1, log_tfidf_2, svm_count_1, svm_count_2, svm_tfidf_1, svm_tfidf_2, knn_count_1, knn_count_2, knn_tfidf_1, knn_tfidf_2]\n",
        "model_str = ['xgb_count_1', 'xgb_tfidf_1', 'xgb_count_1', 'xgb_count_2', 'log_count_1', 'log_count_2', 'log_tfidf_1', 'log_tfidf_2', 'svm_count_1', 'svm_count_2', 'svm_tfidf_1', 'svm_tfidf_2', 'knn_count_1', 'knn_count_2', 'knn_tfidf_1', 'knn_tfidf_2']\n",
        "\n",
        "# Specify the metric to rank the models by\n",
        "all_models, models_by_metric = model_rank(model_list, model_str, 'AUC')\n",
        "models_by_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQYN55Iq5y_F"
      },
      "outputs": [],
      "source": [
        "all_models.to_csv(folder_path+test_num+'all_models.csv', index=False)\n",
        "models_by_metric.to_csv(folder_path+test_num+'models_by_metric.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sdKBq7ETihSJ"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}