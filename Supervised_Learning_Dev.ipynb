{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import, Download, & Variable Statements"
      ],
      "metadata": {
        "id": "cHf_jOR9jOca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import & download statements\n",
        "!git clone https://github.com/d-atallah/implicit_gender_bias.git\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import joblib\n",
        "from implicit_gender_bias import config as cf\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,precision_score, recall_score, f1_score, accuracy_score,roc_curve, roc_auc_score,log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6WzZ3_ujTwL",
        "outputId": "d90d30fd-27a3-4c93-8bd3-05f52ff94042"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'implicit_gender_bias' already exists and is not an empty directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables\n",
        "# Inputs\n",
        "folder_path = cf.filepath()\n",
        "csv_files = ['facebook_wiki_posts','facebook_wiki_responses','fitocracy_posts','fitocracy_responses','reddit_posts','reddit_responses','ted_responses','facebook_congress_posts','annotations','facebook_congress_responses']\n",
        "\n",
        "annotations = pd.read_csv(folder_path+'annotations_combined.csv')\n",
        "#posts_combined = pd.read_csv(folder_path+'posts_combined.csv')\n",
        "#sources_combined = pd.read_csv(folder_path+'sources_combined_output.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPZ-eni9oS-A",
        "outputId": "536b7c36-46c7-4469-a8c9-9874c1539d4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Functions\n"
      ],
      "metadata": {
        "id": "9zRF7xFVjBKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate a model\n",
        "def model_eval(model, X_test, y_test, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluates a specified model using accuracy, precision, recall, F-1 score, AUC, log-Loss, and a confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained model to be evaluated.\n",
        "    - X_test (list or array): Test set features.\n",
        "    - y_test (list or array): True labels.\n",
        "    - y_pred (list or array): Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "    - metrics_df (pd.DataFrame): DataFrame containing the metrics and scores.\n",
        "    - confusion_df (pd.DataFrame): DataFrame containing a confusion matrix.\n",
        "    \"\"\"\n",
        "    # Initialize dataframes\n",
        "    metrics_df = pd.DataFrame(columns=['Metric', 'Score'])\n",
        "    confusion_df = pd.DataFrame(columns=['Actual Positive', 'Actual Negative', 'Predicted Positive', 'Predicted Negative'])\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
        "                                                      'Score': [accuracy, precision, recall, f1]})])\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['AUC'],\n",
        "                                                      'Score': [auc]})])\n",
        "\n",
        "    logloss = log_loss(y_test, model.predict_proba(X_test))\n",
        "    metrics_df = pd.concat([metrics_df, pd.DataFrame({'Metric': ['Log-Loss'],\n",
        "                                                      'Score': [logloss]})])\n",
        "\n",
        "    # Reset index\n",
        "    metrics_df = metrics_df.reset_index(drop=True)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    confusion_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
        "\n",
        "    # Print dataframes\n",
        "    print(\"Metrics:\")\n",
        "    print(metrics_df)\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_df)\n",
        "\n",
        "    return metrics_df, confusion_df"
      ],
      "metadata": {
        "id": "3zLj7yI_jJcQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Validate, Test Split"
      ],
      "metadata": {
        "id": "4OZmlCPsrWD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Annotation only\n",
        "# Set train-test split variables\n",
        "X = annotations['response_text']\n",
        "y = annotations['op_gender_binary']\n",
        "\n",
        "# Perform stratified train-test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Then, split the temp set into validation and test sets\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "PlNBS5XIrOBP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All responses combined\n",
        "# Set train-test split variables\n",
        "X = responses_combined['response_text']\n",
        "y = responses_combined['op_gender_binary']\n",
        "\n",
        "# Perform stratified train-test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=responses_combined['source']\n",
        ")\n",
        "\n",
        "# Then, split the temp set into validation and test sets\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=responses_combined['source']\n",
        ")"
      ],
      "metadata": {
        "id": "-hlRU05nrUOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization"
      ],
      "metadata": {
        "id": "rieYgeuXiOTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words"
      ],
      "metadata": {
        "id": "In_GRUbYiQE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unigram"
      ],
      "metadata": {
        "id": "cr0_GmO7iR5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer\n",
        "vectorizer_count = CountVectorizer()#stop_words='english'\n",
        "X_train_vcount = vectorizer_count.fit_transform(X_train)\n",
        "X_test_vcount = vectorizer_count.transform(X_test)"
      ],
      "metadata": {
        "id": "LmfQg1jRiQT6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the vectorizer and associated data\n",
        "joblib.dump(vectorizer_count,folder_path+'count_vectorizer.pkl')\n",
        "joblib.dump(X_train_vcount, folder_path+'X_train_vcount.pkl')\n",
        "joblib.dump(X_test_vcount, folder_path+'X_test_vectorized.pkl')"
      ],
      "metadata": {
        "id": "pxAyXHupicRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer\n",
        "vectorizer_tfidf = TfidfVectorizer()#stop_words='english'\n",
        "X_train_vtfidf = vectorizer_tfidf.fit_transform(X_train)\n",
        "X_test_vtfidf = vectorizer_tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "s0BIVwHdidtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the vectorizer and associated data\n",
        "joblib.dump(vectorizer_tfidf,folder_path+'tfidf_vectorizer.pkl')\n",
        "joblib.dump(X_train_vtfidf, folder_path+'X_train_vtfidf.pkl')\n",
        "joblib.dump(X_test_vtfidf, folder_path+'X_test_vtfidf.pkl')"
      ],
      "metadata": {
        "id": "Fbj7LCHjifH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest"
      ],
      "metadata": {
        "id": "sdKBq7ETihSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(\n",
        "    rf_classifier, param_grid, cv=3, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train a new Random Forest model with the best parameters\n",
        "best_rf_model = RandomForestClassifier(random_state=42, **best_params)\n",
        "best_rf_model.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_val_pred = best_rf_model.predict(vectorizer_count.transform(X_validation))\n",
        "metrics_val_df, confusion_val_df = model_eval(best_rf_model, vectorizer_count.transform(X_validation), y_validation, y_val_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLwsTS6XsHSI",
        "outputId": "10fa412f-1999-4cbd-ef95-facbc18c39b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n",
            "Metrics:\n",
            "      Metric     Score\n",
            "0   Accuracy  0.592528\n",
            "1  Precision  0.595257\n",
            "2     Recall  0.638677\n",
            "3   F1-Score  0.616203\n",
            "4        AUC  0.591378\n",
            "5   Log-Loss  0.655784\n",
            "\n",
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative\n",
            "Actual Positive                 611                 512\n",
            "Actual Negative                 426                 753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Continue with predictions and evaluation\n",
        "y_pred = model.predict(X_test_vcount)\n",
        "metrics_df, confusion_df = model_eval(model, X_test_vcount, y_test, y_pred)"
      ],
      "metadata": {
        "id": "fASz9iJbifuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_vtfidf, y_train)\n",
        "\n",
        "# Continue with predictions and evaluation\n",
        "y_pred = model.predict(X_test_vtfidf)\n",
        "metrics_df, confusion_df = model_eval(model, X_test_vtfidf, y_test, y_pred)"
      ],
      "metadata": {
        "id": "WHXlM9eTil2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "nFI27kvBio8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model using count vectorization\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = model.predict(X_test_vcount)\n",
        "\n",
        "# Evaluate model\n",
        "metrics_df, confusion_df = model_eval(model, X_test_vtfidf, y_test, y_pred)"
      ],
      "metadata": {
        "id": "GUNvXeKFioZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model using TF-IDF vectorization\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vtfidf, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = model.predict(X_test_vtfidf)\n",
        "\n",
        "# Evaluate model\n",
        "metrics_df, confusion_df = model_eval(model, X_test_vtfidf, y_test, y_pred)"
      ],
      "metadata": {
        "id": "R7W4qtp_isf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bigram"
      ],
      "metadata": {
        "id": "lTpve9C3iuGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer\n",
        "vectorizer_count = CountVectorizer( ngram_range=(2, 2))#stop_words='english',\n",
        "X_train_vcount = vectorizer_count.fit_transform(X_train)\n",
        "X_test_vcount = vectorizer_count.transform(X_test)"
      ],
      "metadata": {
        "id": "UfO9RYnSiukx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the vectorizer and associated data\n",
        "joblib.dump(vectorizer_count,folder_path+'count_vectorizer_bi.pkl')\n",
        "joblib.dump(X_train_vcount, folder_path+'X_train_vcount_bi.pkl')\n",
        "joblib.dump(X_test_vcount, folder_path+'X_test_vectorized_bi.pkl')"
      ],
      "metadata": {
        "id": "0iH5o-5vixx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer\n",
        "vectorizer_tfidf = TfidfVectorizer( ngram_range=(2, 2))#stop_words='english',\n",
        "X_train_vtfidf = vectorizer_tfidf.fit_transform(X_train)\n",
        "X_test_vtfidf = vectorizer_tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "hyMFFjOuizs9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the vectorizer and associated data\n",
        "joblib.dump(vectorizer_tfidf,folder_path+'tfidf_vectorizer_bi.pkl')\n",
        "joblib.dump(X_train_vtfidf, folder_path+'X_train_vtfidf_bi.pkl')\n",
        "joblib.dump(X_test_vtfidf, folder_path+'X_test_vtfidf_bi.pkl')"
      ],
      "metadata": {
        "id": "attu5aSwi0cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(\n",
        "    rf_classifier, param_grid, cv=3, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train a new Random Forest model with the best parameters\n",
        "best_rf_model = RandomForestClassifier(random_state=42, **best_params)\n",
        "best_rf_model.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_val_pred = best_rf_model.predict(vectorizer_count.transform(X_validation))\n",
        "metrics_val_df, confusion_val_df = model_eval(best_rf_model, vectorizer_count.transform(X_validation), y_validation, y_val_pred)\n"
      ],
      "metadata": {
        "id": "KBhbIqn831TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "322iMKuvi26V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model using count vectorization\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = model.predict(X_test_vcount)\n",
        "\n",
        "# Evaluate model\n",
        "metrics_df, confusion_df = model_eval(model, X_test_vtfidf, y_test, y_pred)"
      ],
      "metadata": {
        "id": "bzGqX83Ji357"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model using TF-IDF vectorization\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vtfidf, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = model.predict(X_test_vtfidf)\n",
        "\n",
        "# Evaluate model\n",
        "metrics_df, confusion_df = model_eval(model, X_test_vtfidf, y_test, y_pred)"
      ],
      "metadata": {
        "id": "yfaRjE8Xi6OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with the predictions\n",
        "df_predictions = pd.DataFrame({'Predictions': y_pred})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_predictions.to_csv(log_ngram_pred_output, index=False)"
      ],
      "metadata": {
        "id": "drPvTfPNi8u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "svsUhDyhs-EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid for XGBoost\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "}\n",
        "\n",
        "# Create an XGBoost classifier\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "\n",
        "# Create the GridSearchCV object\n",
        "grid_search = GridSearchCV(\n",
        "    xgb_classifier, param_grid, cv=3, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train a new XGBoost model with the best parameters\n",
        "best_xgb_model = XGBClassifier(random_state=42, **best_params)\n",
        "best_xgb_model.fit(X_train_vcount, y_train)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_val_pred = best_xgb_model.predict(vectorizer_count.transform(X_validation))\n",
        "metrics_val_df, confusion_val_df = model_eval(best_xgb_model, vectorizer_count.transform(X_validation), y_validation, y_val_pred)\n"
      ],
      "metadata": {
        "id": "6HABLYNUs87j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}