{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-atallah/implicit_gender_bias/blob/main/Supervised_Responses_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHf_jOR9jOca"
      },
      "source": [
        "# Import, Download, & Variable Statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6WzZ3_ujTwL",
        "outputId": "5155469d-6a35-4835-d3bf-b982720909af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'implicit_gender_bias' already exists and is not an empty directory.\r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/gibsonce/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/gibsonce/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/gibsonce/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import & download statements\n",
        "# General Statements\n",
        "!git clone https://github.com/d-atallah/implicit_gender_bias.git\n",
        "#! pip install joblib\n",
        "#! pip install shap\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import joblib\n",
        "from implicit_gender_bias import config as cf\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Feature selection & Model tuning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold, cross_validate\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.decomposition import TruncatedSVD,PCA, NMF\n",
        "from sklearn.metrics import confusion_matrix,precision_score, recall_score, f1_score, accuracy_score, roc_curve, roc_auc_score, log_loss, make_scorer, average_precision_score\n",
        "\n",
        "# Model options\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# NLTK resources\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "porter = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPZ-eni9oS-A",
        "outputId": "7601f13f-a6c7-4ce5-e631-48888d597a14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Columns (1,4,6,7,10,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ],
      "source": [
        "# Variables\n",
        "folder_path = '/home/gibsonce/datallah-jaymefis-gibsonce/'\n",
        "\n",
        "# Inputs\n",
        "responses_combined = pd.read_csv(folder_path+'responses_combined.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zRF7xFVjBKo"
      },
      "source": [
        "## Define Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pscLi2HiU1CL"
      },
      "outputs": [],
      "source": [
        "stop_words = {'a',\n",
        " 'about',\n",
        " 'above',\n",
        " 'after',\n",
        " 'again',\n",
        " 'against',\n",
        " 'ain',\n",
        " 'all',\n",
        " 'am',\n",
        " 'an',\n",
        " 'and',\n",
        " 'any',\n",
        " 'are',\n",
        " 'aren',\n",
        " \"aren't\",\n",
        " 'as',\n",
        " 'at',\n",
        " 'be',\n",
        " 'because',\n",
        " 'been',\n",
        " 'before',\n",
        " 'being',\n",
        " 'below',\n",
        " 'between',\n",
        " 'both',\n",
        " 'but',\n",
        " 'by',\n",
        " 'can',\n",
        " 'couldn',\n",
        " \"couldn't\",\n",
        " 'd',\n",
        " 'did',\n",
        " 'didn',\n",
        " \"didn't\",\n",
        " 'do',\n",
        " 'does',\n",
        " 'doesn',\n",
        " \"doesn't\",\n",
        " 'doing',\n",
        " 'don',\n",
        " \"don't\",\n",
        " 'down',\n",
        " 'during',\n",
        " 'each',\n",
        " 'few',\n",
        " 'for',\n",
        " 'from',\n",
        " 'further',\n",
        " 'had',\n",
        " 'hadn',\n",
        " \"hadn't\",\n",
        " 'has',\n",
        " 'hasn',\n",
        " \"hasn't\",\n",
        " 'have',\n",
        " 'haven',\n",
        " \"haven't\",\n",
        " 'having',\n",
        " #'he',\n",
        " #'her',\n",
        " 'here',\n",
        " #'hers',\n",
        " #'herself',\n",
        " #'him',\n",
        " #'himself',\n",
        " #'his',\n",
        " 'how',\n",
        " 'i',\n",
        " 'if',\n",
        " 'in',\n",
        " 'into',\n",
        " 'is',\n",
        " 'isn',\n",
        " \"isn't\",\n",
        " 'it',\n",
        " \"it's\",\n",
        " 'its',\n",
        " 'itself',\n",
        " 'just',\n",
        " 'll',\n",
        " 'm',\n",
        " 'ma',\n",
        " 'me',\n",
        " 'mightn',\n",
        " \"mightn't\",\n",
        " 'more',\n",
        " 'most',\n",
        " 'mustn',\n",
        " \"mustn't\",\n",
        " 'my',\n",
        " 'myself',\n",
        " 'needn',\n",
        " \"needn't\",\n",
        " 'no',\n",
        " 'nor',\n",
        " 'not',\n",
        " 'now',\n",
        " 'o',\n",
        " 'of',\n",
        " 'off',\n",
        " 'on',\n",
        " 'once',\n",
        " 'only',\n",
        " 'or',\n",
        " 'other',\n",
        " 'our',\n",
        " 'ours',\n",
        " 'ourselves',\n",
        " 'out',\n",
        " 'over',\n",
        " 'own',\n",
        " 're',\n",
        " 's',\n",
        " 'same',\n",
        " 'shan',\n",
        " \"shan't\",\n",
        " #'she',\n",
        " #\"she's\",\n",
        " 'should',\n",
        " \"should've\",\n",
        " 'shouldn',\n",
        " \"shouldn't\",\n",
        " 'so',\n",
        " 'some',\n",
        " 'such',\n",
        " 't',\n",
        " 'than',\n",
        " 'that',\n",
        " \"that'll\",\n",
        " 'the',\n",
        " 'their',\n",
        " 'theirs',\n",
        " 'them',\n",
        " 'themselves',\n",
        " 'then',\n",
        " 'there',\n",
        " 'these',\n",
        " 'they',\n",
        " 'this',\n",
        " 'those',\n",
        " 'through',\n",
        " 'to',\n",
        " 'too',\n",
        " 'under',\n",
        " 'until',\n",
        " 'up',\n",
        " 've',\n",
        " 'very',\n",
        " 'was',\n",
        " 'wasn',\n",
        " \"wasn't\",\n",
        " 'we',\n",
        " 'were',\n",
        " 'weren',\n",
        " \"weren't\",\n",
        " 'what',\n",
        " 'when',\n",
        " 'where',\n",
        " 'which',\n",
        " 'while',\n",
        " 'who',\n",
        " 'whom',\n",
        " 'why',\n",
        " 'will',\n",
        " 'with',\n",
        " 'won',\n",
        " \"won't\",\n",
        " 'wouldn',\n",
        " \"wouldn't\",\n",
        " 'y',\n",
        " 'you',\n",
        " \"you'd\",\n",
        " \"you'll\",\n",
        " \"you're\",\n",
        " \"you've\",\n",
        " 'your',\n",
        " 'yours',\n",
        " 'yourself',\n",
        " 'yourselves'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1jh0q60RcvF"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Applies text preprocessing to a given text, including:\n",
        "    - Removing special characters and digits\n",
        "    - Converting to lowercase\n",
        "    - Tokenization and removing stopwords\n",
        "    - Lemmatization and stemming\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): Input text to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "    - processed_text (str): Preprocessed text after applying the specified steps.\n",
        "    \"\"\"\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenization and removing stopwords\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Lemmatization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    #tokens = [porter.stem(word) for word in tokens]\n",
        "\n",
        "    # Rejoin tokens into a processed text\n",
        "    processed_text = ' '.join(tokens)\n",
        "\n",
        "    return processed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ2T60xP1laV"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess\n",
        "def preprocess_batch(data, batch_index):\n",
        "    processed_data = list(map(preprocess_text, data))\n",
        "    return processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZ9IeKzIkjZx"
      },
      "outputs": [],
      "source": [
        "def model_rank(model_list, model_str, metric):\n",
        "    \"\"\"\n",
        "    Finds the model with the best score based on a specified metric.\n",
        "\n",
        "    Parameters:\n",
        "    - models_list (list): List of dictionaries, each representing a model's details.\n",
        "    - model_str (list): List of model names corresponding to models_list.\n",
        "    - metric (str): Metric to rank the models by (e.g., 'Accuracy', 'F1-Score').\n",
        "\n",
        "    Returns:\n",
        "    - all_models (pd.DataFrame): DataFrame with metric scores and model names.\n",
        "    - models_by_metric (pd.DataFrame): DataFrame filtered by the specified metric and sorted in descending order.\n",
        "    \"\"\"\n",
        "    all_models = [model_dict['metrics'].assign(Model=model_name) for model_dict, model_name in zip(model_list, model_str)]\n",
        "\n",
        "    # Concatenate the DataFrames in the list\n",
        "    all_models = pd.concat(all_models, ignore_index=True)\n",
        "\n",
        "\n",
        "    # Sort the DataFrame by the specified metric in descending order\n",
        "    models_by_metric = all_models[all_models['Metric'] == metric].sort_values(by='Score', ascending=False)\n",
        "\n",
        "    return all_models, models_by_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OZmlCPsrWD6"
      },
      "source": [
        "# Train, Validate, Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hlRU05nrUOB"
      },
      "outputs": [],
      "source": [
        "# All responses combined\n",
        "# Set train-test split variables\n",
        "X = responses_combined['response_text']\n",
        "y = responses_combined['op_gender_binary']\n",
        "\n",
        "# Perform stratified train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=responses_combined['source']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_TrBtCQ1laW"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9QTYtTI1laW",
        "outputId": "1494726c-2d93-4f7b-c73b-042ec00a7471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 1...\n",
            "Batch 1 processed in 1.04 seconds.\n",
            "Total time elapsed: 1.04 minutes.\n",
            "Processing batch 2...\n",
            "Batch 2 processed in 1.03 seconds.\n",
            "Total time elapsed: 2.06 minutes.\n",
            "Processing batch 3...\n",
            "Batch 3 processed in 1.02 seconds.\n",
            "Total time elapsed: 3.09 minutes.\n",
            "Processing batch 4...\n",
            "Batch 4 processed in 1.03 seconds.\n",
            "Total time elapsed: 4.11 minutes.\n",
            "Processing batch 5...\n",
            "Batch 5 processed in 1.02 seconds.\n",
            "Total time elapsed: 5.13 minutes.\n",
            "Processing batch 6...\n",
            "Batch 6 processed in 1.03 seconds.\n",
            "Total time elapsed: 6.16 minutes.\n",
            "Processing batch 7...\n",
            "Batch 7 processed in 1.02 seconds.\n",
            "Total time elapsed: 7.18 minutes.\n",
            "Processing batch 8...\n",
            "Batch 8 processed in 1.03 seconds.\n",
            "Total time elapsed: 8.21 minutes.\n",
            "Processing batch 9...\n",
            "Batch 9 processed in 1.02 seconds.\n",
            "Total time elapsed: 9.23 minutes.\n",
            "Processing batch 10...\n",
            "Batch 10 processed in 1.02 seconds.\n",
            "Total time elapsed: 10.24 minutes.\n",
            "Processing batch 11...\n",
            "Batch 11 processed in 1.02 seconds.\n",
            "Total time elapsed: 11.27 minutes.\n",
            "Processing batch 12...\n",
            "Batch 12 processed in 1.02 seconds.\n",
            "Total time elapsed: 12.29 minutes.\n",
            "Processing batch 13...\n",
            "Batch 13 processed in 1.03 seconds.\n",
            "Total time elapsed: 13.32 minutes.\n",
            "Processing batch 14...\n",
            "Batch 14 processed in 1.02 seconds.\n",
            "Total time elapsed: 14.34 minutes.\n",
            "Processing batch 15...\n",
            "Batch 15 processed in 1.02 seconds.\n",
            "Total time elapsed: 15.37 minutes.\n",
            "Processing batch 16...\n",
            "Batch 16 processed in 1.02 seconds.\n",
            "Total time elapsed: 16.39 minutes.\n",
            "Processing batch 17...\n",
            "Batch 17 processed in 1.02 seconds.\n",
            "Total time elapsed: 17.41 minutes.\n",
            "Processing batch 18...\n",
            "Batch 18 processed in 1.02 seconds.\n",
            "Total time elapsed: 18.44 minutes.\n",
            "Processing batch 19...\n",
            "Batch 19 processed in 1.03 seconds.\n",
            "Total time elapsed: 19.46 minutes.\n",
            "Processing batch 20...\n",
            "Batch 20 processed in 1.14 seconds.\n",
            "Total time elapsed: 20.61 minutes.\n",
            "Processing batch 21...\n",
            "Batch 21 processed in 1.02 seconds.\n",
            "Total time elapsed: 21.63 minutes.\n",
            "Processing batch 22...\n",
            "Batch 22 processed in 1.02 seconds.\n",
            "Total time elapsed: 22.65 minutes.\n",
            "Processing batch 23...\n",
            "Batch 23 processed in 1.02 seconds.\n",
            "Total time elapsed: 23.67 minutes.\n",
            "Processing batch 24...\n",
            "Batch 24 processed in 1.02 seconds.\n",
            "Total time elapsed: 24.70 minutes.\n",
            "Processing batch 25...\n",
            "Batch 25 processed in 1.02 seconds.\n",
            "Total time elapsed: 25.72 minutes.\n",
            "Processing batch 26...\n",
            "Batch 26 processed in 1.03 seconds.\n",
            "Total time elapsed: 26.74 minutes.\n",
            "Processing batch 27...\n",
            "Batch 27 processed in 1.02 seconds.\n",
            "Total time elapsed: 27.77 minutes.\n",
            "Processing batch 28...\n",
            "Batch 28 processed in 1.02 seconds.\n",
            "Total time elapsed: 28.79 minutes.\n",
            "Processing batch 29...\n",
            "Batch 29 processed in 1.02 seconds.\n",
            "Total time elapsed: 29.80 minutes.\n",
            "Processing batch 30...\n",
            "Batch 30 processed in 1.03 seconds.\n",
            "Total time elapsed: 30.83 minutes.\n",
            "Processing batch 31...\n",
            "Batch 31 processed in 1.02 seconds.\n",
            "Total time elapsed: 31.85 minutes.\n",
            "Processing batch 32...\n",
            "Batch 32 processed in 1.02 seconds.\n",
            "Total time elapsed: 32.88 minutes.\n",
            "Processing batch 33...\n",
            "Batch 33 processed in 1.02 seconds.\n",
            "Total time elapsed: 33.90 minutes.\n",
            "Processing batch 34...\n",
            "Batch 34 processed in 1.02 seconds.\n",
            "Total time elapsed: 34.92 minutes.\n",
            "Processing batch 35...\n",
            "Batch 35 processed in 1.02 seconds.\n",
            "Total time elapsed: 35.95 minutes.\n",
            "Processing batch 36...\n",
            "Batch 36 processed in 1.02 seconds.\n",
            "Total time elapsed: 36.97 minutes.\n",
            "Processing batch 37...\n",
            "Batch 37 processed in 1.02 seconds.\n",
            "Total time elapsed: 37.99 minutes.\n",
            "Processing batch 38...\n",
            "Batch 38 processed in 1.03 seconds.\n",
            "Total time elapsed: 39.02 minutes.\n",
            "Processing batch 39...\n",
            "Batch 39 processed in 1.02 seconds.\n",
            "Total time elapsed: 40.04 minutes.\n",
            "Processing batch 40...\n",
            "Batch 40 processed in 1.02 seconds.\n",
            "Total time elapsed: 41.06 minutes.\n",
            "Processing batch 41...\n",
            "Batch 41 processed in 1.03 seconds.\n",
            "Total time elapsed: 42.09 minutes.\n",
            "Processing batch 42...\n",
            "Batch 42 processed in 1.02 seconds.\n",
            "Total time elapsed: 43.11 minutes.\n",
            "Processing batch 43...\n",
            "Batch 43 processed in 0.39 seconds.\n",
            "Total time elapsed: 43.50 minutes.\n"
          ]
        }
      ],
      "source": [
        "# Specify the batch size\n",
        "batch_size = 500000\n",
        "# Create batches\n",
        "X_train_batches = [X_train[i:i + batch_size] for i in range(0, len(X_train), batch_size)]\n",
        "# Preprocess data storage\n",
        "X_train_preprocessed = []\n",
        "# Initialize total time elapsed\n",
        "total_start_time = time.time()\n",
        "\n",
        "for batch_index, batch in enumerate(X_train_batches):\n",
        "    print(f\"Processing batch {batch_index + 1}...\")\n",
        "    # Start time for each batch\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Run preprocessing\n",
        "    X_train_preprocessed.extend(preprocess_batch(batch, batch_index))\n",
        "\n",
        "    # End time for each batch\n",
        "    end_time = time.time()\n",
        "    total_end_time = time.time()\n",
        "\n",
        "    # Calculate elapsed time for the batch\n",
        "    elapsed_time = end_time - start_time\n",
        "    total_elapsed_time = total_end_time - total_start_time\n",
        "    print(f\"Batch {batch_index + 1} processed in {elapsed_time/60:.2f} seconds.\")\n",
        "    print(f\"Total time elapsed: {total_elapsed_time/60:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "gm2B8pR81laW",
        "outputId": "44e66d89-616e-48fb-fc9f-34e426fd4f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 1...\n",
            "Batch 1 processed in 1.02 seconds.\n",
            "Total time elapsed: 1.02 minutes.\n",
            "Processing batch 2...\n",
            "Batch 2 processed in 1.02 seconds.\n",
            "Total time elapsed: 2.04 minutes.\n",
            "Processing batch 3...\n",
            "Batch 3 processed in 1.02 seconds.\n",
            "Total time elapsed: 3.06 minutes.\n",
            "Processing batch 4...\n",
            "Batch 4 processed in 1.02 seconds.\n",
            "Total time elapsed: 4.09 minutes.\n",
            "Processing batch 5...\n",
            "Batch 5 processed in 1.02 seconds.\n",
            "Total time elapsed: 5.11 minutes.\n",
            "Processing batch 6...\n",
            "Batch 6 processed in 1.03 seconds.\n",
            "Total time elapsed: 6.14 minutes.\n",
            "Processing batch 7...\n",
            "Batch 7 processed in 1.02 seconds.\n",
            "Total time elapsed: 7.16 minutes.\n",
            "Processing batch 8...\n",
            "Batch 8 processed in 1.02 seconds.\n",
            "Total time elapsed: 8.18 minutes.\n",
            "Processing batch 9...\n",
            "Batch 9 processed in 1.03 seconds.\n",
            "Total time elapsed: 9.21 minutes.\n",
            "Processing batch 10...\n",
            "Batch 10 processed in 1.02 seconds.\n",
            "Total time elapsed: 10.23 minutes.\n",
            "Processing batch 11...\n",
            "Batch 11 processed in 0.61 seconds.\n",
            "Total time elapsed: 10.84 minutes.\n"
          ]
        }
      ],
      "source": [
        "# Specify the batch size\n",
        "batch_size = 500000\n",
        "# Create batches\n",
        "X_test_batches = [X_test[i:i + batch_size] for i in range(0, len(X_test), batch_size)]\n",
        "# Preprocess data storage\n",
        "X_test_preprocessed = []\n",
        "# Initialize total time elapsed\n",
        "total_start_time = time.time()\n",
        "\n",
        "for batch_index, batch in enumerate(X_test_batches):\n",
        "    print(f\"Processing batch {batch_index + 1}...\")\n",
        "\n",
        "    # Start time for each batch\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Run preprocessing\n",
        "    X_test_preprocessed.extend(preprocess_batch(batch, batch_index))\n",
        "\n",
        "    # End time for each batch\n",
        "    end_time = time.time()\n",
        "    total_end_time = time.time()\n",
        "\n",
        "    # Calculate elapsed time for the batch\n",
        "    elapsed_time = end_time - start_time\n",
        "    total_elapsed_time = total_end_time - total_start_time\n",
        "    print(f\"Batch {batch_index + 1} processed in {elapsed_time/60:.2f} seconds.\")\n",
        "    print(f\"Total time elapsed: {total_elapsed_time/60:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GPvWKjI1laX"
      },
      "outputs": [],
      "source": [
        "# Convert series to DataFrames\n",
        "df_X_train_preprocessed = pd.DataFrame(X_train_preprocessed, columns=['text'])\n",
        "df_X_test_preprocessed = pd.DataFrame(X_test_preprocessed, columns=['text'])\n",
        "df_y_train = pd.DataFrame({'op_gender_binary': y_train})\n",
        "df_y_test = pd.DataFrame({'op_gender_binary': y_test})\n",
        "\n",
        "# Remove Nulls\n",
        "non_nan_indices_train = ~df_X_train_preprocessed.isnull()\n",
        "non_nan_indices_test = ~df_X_test_preprocessed.isnull()\n",
        "\n",
        "# Filter y_train and y_test using the non-NaN indices\n",
        "y_train_filtered = df_y_train[non_nan_indices_train]\n",
        "y_test_filtered = df_y_test[non_nan_indices_test]\n",
        "\n",
        "# Filter X_train and X_test to remove NaN records\n",
        "X_train_filtered = df_X_train_preprocessed[non_nan_indices_train]\n",
        "X_test_filtered = df_X_test_preprocessed[non_nan_indices_test]\n",
        "\n",
        "# Save DataFrames to CSV files\n",
        "X_train_filtered.to_csv(folder_path + 'X_train_preprocessed.csv', index=False)\n",
        "X_test_filtered.to_csv(folder_path + 'X_test_preprocessed.csv', index=False)\n",
        "y_train_filtered.to_csv(folder_path + 'y_train.csv', index=False)\n",
        "y_test_filtered.to_csv(folder_path + 'y_test.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sdKBq7ETihSJ"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}