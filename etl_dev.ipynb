{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f75cdb",
   "metadata": {},
   "source": [
    "# Import, Download, & Variable Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a49601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gibsonce/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/gibsonce/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import & download statements\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d201be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "extract_path = '/home/gibsonce/datallah-jaymefis-gibsonce/'\n",
    "csv_files = ['facebook_wiki_posts','facebook_wiki_responses','fitocracy_posts','fitocracy_responses','reddit_posts','reddit_responses','ted_responses','facebook_congress_posts','facebook_congress_responses','annotations']\n",
    "log_ngram_pred_path = '/home/gibsonce/datallah-jaymefis-gibsonce/log_ngram_preds.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab67c14a",
   "metadata": {},
   "source": [
    "# Load Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a4f171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Pandas Dataframes\n",
    "facebook_wiki_posts_raw = pd.read_csv(extract_path+'facebook_wiki_posts.csv')\n",
    "facebook_wiki_responses_raw = pd.read_csv(extract_path+'facebook_wiki_responses.csv')\n",
    "fitocracy_posts_raw = pd.read_csv(extract_path+'fitocracy_posts.csv')\n",
    "fitocracy_responses_raw = pd.read_csv(extract_path+'fitocracy_responses.csv')\n",
    "reddit_posts_raw = pd.read_csv(extract_path+'reddit_posts.csv')\n",
    "reddit_responses_raw = pd.read_csv(extract_path+'reddit_responses.csv')\n",
    "ted_responses_raw = pd.read_csv(extract_path+'ted_responses.csv')\n",
    "annotations_raw = pd.read_csv(extract_path+'annotations.csv')\n",
    "facebook_congress_posts_raw = pd.read_csv(extract_path+'facebook_congress_posts.csv')\n",
    "facebook_congress_responses_raw = pd.read_csv(extract_path+'facebook_congress_responses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4388b8",
   "metadata": {},
   "source": [
    "# Source Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8583971",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b52b2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy Dataframes to not overwrite original\n",
    "def reset_dfs():\n",
    "    global facebook_wiki_posts, facebook_wiki_responses, fitocracy_posts, fitocracy_responses,reddit_posts, reddit_responses,ted_responses, annotations,facebook_congress_posts, facebook_congress_responses\n",
    "    \n",
    "    facebook_wiki_posts = facebook_wiki_posts_raw.reset_index()\n",
    "    facebook_wiki_responses = facebook_wiki_responses_raw.reset_index()\n",
    "    fitocracy_posts = fitocracy_posts_raw.reset_index()\n",
    "    fitocracy_responses = fitocracy_responses_raw.reset_index()\n",
    "    reddit_posts = reddit_posts_raw.reset_index()\n",
    "    reddit_responses = reddit_responses_raw.reset_index()\n",
    "    ted_responses = ted_responses_raw.reset_index()\n",
    "    annotations = annotations_raw.reset_index()\n",
    "    facebook_congress_posts = facebook_congress_posts_raw.reset_index()\n",
    "    facebook_congress_responses = facebook_congress_responses_raw.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b3496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create UID\n",
    "def create_id(df):\n",
    "    df['sourceID'] = df['source']+df['index'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66fc76fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop common columns then merge post and response\n",
    "def post_merge(post_df, response_df):\n",
    "    temp_df = response_df.drop('op_gender', axis=1)\n",
    "    merged = pd.merge(post_df, temp_df, on=['op_id', 'post_id'], how='inner')\n",
    "    merged = merged.reset_index()\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec1254",
   "metadata": {},
   "source": [
    "## Responses Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff9219d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset dataframes to raw data\n",
    "reset_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8874540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source field\n",
    "facebook_wiki_responses['source'] = 'FW'\n",
    "fitocracy_responses['source'] = 'F'\n",
    "reddit_responses['source'] = 'R'\n",
    "facebook_congress_responses['source'] = 'FC'\n",
    "ted_responses['source'] = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202e9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through sources and create UID\n",
    "sources = [facebook_wiki_responses,fitocracy_responses,reddit_responses,facebook_congress_responses,ted_responses]\n",
    "for source in sources:\n",
    "    create_id(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10592022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union tables\n",
    "responses_combined = pd.concat(sources, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38a446c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map gender to binary indicator\n",
    "responses_combined['op_gender_binary'] = responses_combined['op_gender'].map({'W': 0, 'M': 1})\n",
    "\n",
    "# Drop NA text\n",
    "responses_combined = responses_combined.dropna(subset=['response_text'])\n",
    "responses_combined = responses_combined.dropna(subset=['op_gender_binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "072fe801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>op_id</th>\n",
       "      <th>op_gender</th>\n",
       "      <th>post_id</th>\n",
       "      <th>responder_id</th>\n",
       "      <th>response_text</th>\n",
       "      <th>op_name</th>\n",
       "      <th>op_category</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceID</th>\n",
       "      <th>responder_gender</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>responder_gender_visible</th>\n",
       "      <th>op_gender_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>Is this watch going to make it to LaPorte county?</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Anything for Wilmington area</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Darlene</td>\n",
       "      <td>Thanks, please keep us posted.</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Cheryl</td>\n",
       "      <td>Thanks Byron</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>[[STICKER]]</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     op_id op_gender  post_id responder_id  \\\n",
       "0      0  11679984         M        0     Michelle   \n",
       "1      1  11679984         M        0      Melissa   \n",
       "2      2  11679984         M        0      Darlene   \n",
       "3      3  11679984         M        0       Cheryl   \n",
       "4      4  11679984         M        0      Melissa   \n",
       "\n",
       "                                       response_text        op_name  \\\n",
       "0  Is this watch going to make it to LaPorte county?  Byron Miranda   \n",
       "1                       Anything for Wilmington area  Byron Miranda   \n",
       "2                     Thanks, please keep us posted.  Byron Miranda   \n",
       "3                                       Thanks Byron  Byron Miranda   \n",
       "4                                        [[STICKER]]  Byron Miranda   \n",
       "\n",
       "                                  op_category source sourceID  \\\n",
       "0  Wikipedia_American_television_news_anchors     FW      FW0   \n",
       "1  Wikipedia_American_television_news_anchors     FW      FW1   \n",
       "2  Wikipedia_American_television_news_anchors     FW      FW2   \n",
       "3  Wikipedia_American_television_news_anchors     FW      FW3   \n",
       "4  Wikipedia_American_television_news_anchors     FW      FW4   \n",
       "\n",
       "  responder_gender subreddit responder_gender_visible  op_gender_binary  \n",
       "0              NaN       NaN                      NaN               1.0  \n",
       "1              NaN       NaN                      NaN               1.0  \n",
       "2              NaN       NaN                      NaN               1.0  \n",
       "3              NaN       NaN                      NaN               1.0  \n",
       "4              NaN       NaN                      NaN               1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5baa97",
   "metadata": {},
   "source": [
    "## Posts Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c6c6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset dataframes to raw data\n",
    "reset_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce82303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source field\n",
    "facebook_wiki_posts['source'] = 'FW'\n",
    "fitocracy_posts['source'] = 'F'\n",
    "reddit_posts['source'] = 'R'\n",
    "facebook_congress_posts['source'] = 'FC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d672f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through sources and create UID\n",
    "sources = [facebook_wiki_posts,fitocracy_posts,reddit_posts,facebook_congress_posts]\n",
    "for source in sources:\n",
    "    create_id(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb20406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>op_id</th>\n",
       "      <th>op_gender</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_type</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceID</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>op_gender_visible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Tornado watch in effect tonight. Be safe. Plea...</td>\n",
       "      <td>photo</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>photo</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Temps warming up for the holiday weekend! I wi...</td>\n",
       "      <td>photo</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Showers heading this way ..</td>\n",
       "      <td>photo</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Storm potential update...feel free to share th...</td>\n",
       "      <td>photo</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     op_id op_gender  post_id  \\\n",
       "0      0  11679984         M        0   \n",
       "1      1  11679984         M        1   \n",
       "2      2  11679984         M        2   \n",
       "3      3  11679984         M        3   \n",
       "4      4  11679984         M        4   \n",
       "\n",
       "                                           post_text post_type source  \\\n",
       "0  Tornado watch in effect tonight. Be safe. Plea...     photo     FW   \n",
       "1                                                NaN     photo     FW   \n",
       "2  Temps warming up for the holiday weekend! I wi...     photo     FW   \n",
       "3                        Showers heading this way ..     photo     FW   \n",
       "4  Storm potential update...feel free to share th...     photo     FW   \n",
       "\n",
       "  sourceID subreddit op_gender_visible  \n",
       "0      FW0       NaN               NaN  \n",
       "1      FW1       NaN               NaN  \n",
       "2      FW2       NaN               NaN  \n",
       "3      FW3       NaN               NaN  \n",
       "4      FW4       NaN               NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Union tables\n",
    "posts_combined = pd.concat(sources, ignore_index=True)\n",
    "posts_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce46a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map gender to binary indicator\n",
    "posts_combined['op_gender_binary'] = posts_combined['op_gender'].map({'W': 0, 'M': 1})\n",
    "\n",
    "# Drop NA text\n",
    "posts_combined = posts_combined.dropna(subset=['post_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012c193",
   "metadata": {},
   "source": [
    "## Merging Posts and Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f53d29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset dataframes to raw data\n",
    "reset_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "972ca18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop common columns\n",
    "reddit_responses = reddit_responses.drop('subreddit', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c40fdae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge applicable dataframes\n",
    "facebook_wiki_merged = post_merge(facebook_wiki_posts, facebook_wiki_responses)\n",
    "fitocracy_merged = post_merge(fitocracy_posts, fitocracy_responses)\n",
    "reddit_merged = post_merge(reddit_posts, reddit_responses)\n",
    "facebook_congress_merged = post_merge(facebook_congress_posts, facebook_congress_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4318a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source field\n",
    "facebook_wiki_merged['source'] = 'FW'\n",
    "fitocracy_merged['source'] = 'F'\n",
    "reddit_merged['source'] = 'R'\n",
    "facebook_congress_merged['source'] = 'FC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7032428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through sources and create UID\n",
    "sources = [facebook_wiki_merged,fitocracy_merged,reddit_merged,facebook_congress_merged]\n",
    "for source in sources:\n",
    "    create_id(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6294be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>index_x</th>\n",
       "      <th>op_id</th>\n",
       "      <th>op_gender</th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>post_type</th>\n",
       "      <th>index_y</th>\n",
       "      <th>responder_id</th>\n",
       "      <th>response_text</th>\n",
       "      <th>op_name</th>\n",
       "      <th>op_category</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceID</th>\n",
       "      <th>responder_gender</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>op_gender_visible</th>\n",
       "      <th>responder_gender_visible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Tornado watch in effect tonight. Be safe. Plea...</td>\n",
       "      <td>photo</td>\n",
       "      <td>0</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>Is this watch going to make it to LaPorte county?</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Tornado watch in effect tonight. Be safe. Plea...</td>\n",
       "      <td>photo</td>\n",
       "      <td>1</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Anything for Wilmington area</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Tornado watch in effect tonight. Be safe. Plea...</td>\n",
       "      <td>photo</td>\n",
       "      <td>2</td>\n",
       "      <td>Darlene</td>\n",
       "      <td>Thanks, please keep us posted.</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Tornado watch in effect tonight. Be safe. Plea...</td>\n",
       "      <td>photo</td>\n",
       "      <td>3</td>\n",
       "      <td>Cheryl</td>\n",
       "      <td>Thanks Byron</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11679984</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Tornado watch in effect tonight. Be safe. Plea...</td>\n",
       "      <td>photo</td>\n",
       "      <td>4</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>[[STICKER]]</td>\n",
       "      <td>Byron Miranda</td>\n",
       "      <td>Wikipedia_American_television_news_anchors</td>\n",
       "      <td>FW</td>\n",
       "      <td>FW4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  index_x     op_id op_gender  post_id  \\\n",
       "0      0        0  11679984         M        0   \n",
       "1      1        0  11679984         M        0   \n",
       "2      2        0  11679984         M        0   \n",
       "3      3        0  11679984         M        0   \n",
       "4      4        0  11679984         M        0   \n",
       "\n",
       "                                           post_text post_type  index_y  \\\n",
       "0  Tornado watch in effect tonight. Be safe. Plea...     photo        0   \n",
       "1  Tornado watch in effect tonight. Be safe. Plea...     photo        1   \n",
       "2  Tornado watch in effect tonight. Be safe. Plea...     photo        2   \n",
       "3  Tornado watch in effect tonight. Be safe. Plea...     photo        3   \n",
       "4  Tornado watch in effect tonight. Be safe. Plea...     photo        4   \n",
       "\n",
       "  responder_id                                      response_text  \\\n",
       "0     Michelle  Is this watch going to make it to LaPorte county?   \n",
       "1      Melissa                       Anything for Wilmington area   \n",
       "2      Darlene                     Thanks, please keep us posted.   \n",
       "3       Cheryl                                       Thanks Byron   \n",
       "4      Melissa                                        [[STICKER]]   \n",
       "\n",
       "         op_name                                 op_category source sourceID  \\\n",
       "0  Byron Miranda  Wikipedia_American_television_news_anchors     FW      FW0   \n",
       "1  Byron Miranda  Wikipedia_American_television_news_anchors     FW      FW1   \n",
       "2  Byron Miranda  Wikipedia_American_television_news_anchors     FW      FW2   \n",
       "3  Byron Miranda  Wikipedia_American_television_news_anchors     FW      FW3   \n",
       "4  Byron Miranda  Wikipedia_American_television_news_anchors     FW      FW4   \n",
       "\n",
       "  responder_gender subreddit op_gender_visible responder_gender_visible  \n",
       "0              NaN       NaN               NaN                      NaN  \n",
       "1              NaN       NaN               NaN                      NaN  \n",
       "2              NaN       NaN               NaN                      NaN  \n",
       "3              NaN       NaN               NaN                      NaN  \n",
       "4              NaN       NaN               NaN                      NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Union tables\n",
    "sources_combined = pd.concat(sources, ignore_index=True)\n",
    "sources_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4281971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map gender to binary indicator\n",
    "sources_combined['op_gender_binary'] = sources_combined['op_gender'].map({'W': 0, 'M': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555e4ed6",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f8618b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train-test split variables\n",
    "X = responses_combined['response_text']\n",
    "y = responses_combined['op_gender_binary']\n",
    "\n",
    "# Perform stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=responses_combined['source']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab564473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing and tokenization\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85608ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with the predictions\n",
    "df_predictions = pd.DataFrame({'Predictions': y_pred})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_predictions.to_csv(log_ngram_pred_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd184bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de3ee0",
   "metadata": {},
   "source": [
    "# Unused Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48979be5",
   "metadata": {},
   "source": [
    "# Text field preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    # Tokenization, remove stop words, and lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "sources_combined['post_text_processed'] = sources_combined['post_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22fad0",
   "metadata": {},
   "source": [
    "!pip install pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f942034",
   "metadata": {},
   "source": [
    "### Variables\n",
    "extract_path = '/home/gibsonce/datallah-jaymefis-gibsonce/'\n",
    "csv_files = ['facebook_wiki_posts','facebook_wiki_responses','fitocracy_posts','fitocracy_responses','reddit_posts','reddit_responses','ted_responses','facebook_congress_posts','facebook_congress_responses','annotations']\n",
    "\n",
    "### Spark session\n",
    "spark = SparkSession.builder.appName('example').getOrCreate()\n",
    "\n",
    "### Spark Dataframes\n",
    "facebook_wiki_posts = spark.read.csv(extract_path+'facebook_wiki_posts.csv', header=True, inferSchema=True)\n",
    "facebook_wiki_responses = spark.read.csv(extract_path+'facebook_wiki_responses.csv', header=True, inferSchema=True)\n",
    "fitocracy_posts = spark.read.csv(extract_path+'fitocracy_posts.csv', header=True, inferSchema=True)\n",
    "fitocracy_responses = spark.read.csv(extract_path+'fitocracy_responses.csv', header=True, inferSchema=True)\n",
    "reddit_posts = spark.read.csv(extract_path+'reddit_posts.csv', header=True, inferSchema=True)\n",
    "reddit_responses = spark.read.csv(extract_path+'reddit_responses.csv', header=True, inferSchema=True)\n",
    "ted_responses = spark.read.csv(extract_path+'ted_responses.csv', header=True, inferSchema=True)\n",
    "annotations = spark.read.csv(extract_path+'annotations.csv', header=True, inferSchema=True)\n",
    "facebook_congress_posts = spark.read.csv(extract_path+'facebook_congress_posts.csv', header=True, inferSchema=True)\n",
    "facebook_congress_responses = spark.read.csv(extract_path+'facebook_congress_responses.csv', header=True, inferSchema=True)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
